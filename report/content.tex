\section{Giới thiệu}

\subsection{Mục tiêu bài lab}
Bài lab này nhằm xây dựng pipeline phân loại thư rác sử dụng thuật toán \texttt{Naive Bayes}, được huấn luyện trên một phần của tập dữ liệu Enron-Spam và có khả năng phân loại email thành hai nhóm: spam và ham (thư thường).

\subsection{Tập dữ liệu}
Bộ dữ liệu được sử dụng là một phần của bộ Enron-Spam, được chia thành hai tập:
\begin{itemize}
    \item \texttt{train.csv}: Tập huấn luyện, gồm \textbf{27.284} email. (Spam: 13.861, Ham: 13.423)
    \item \texttt{val.csv}: Tập đánh giá (validation), gồm \textbf{3.084} email. (Spam: 1.561, Ham: 1.523)
\end{itemize}
Mỗi tập chứa các cột sẽ được sử dụng để train là: \texttt{Subject} (tiêu đề), \texttt{Message} (nội dung), và \texttt{Spam/Ham} (nhãn).

\section{Tiền xử lý dữ liệu}

\subsection{Làm sạch và chuẩn hóa}
Thực hiện các bước tiền xử lý sau cho cả tiêu đề và nội dung của mỗi email:

\begin{enumerate}
    \item \textbf{Xử lý giá trị thiếu}: Thay thế giá trị NaN trong các cột liên quan bằng chuỗi rỗng.
    \item \textbf{Kết hợp Subject và Message}: Tạo một trường văn bản duy nhất để phân tích.
    \item \textbf{Tạo token đặc trưng}: Dựa trên dữ liệu thô, tạo ra các token đặc biệt để nắm bắt các đặc điểm như tỷ lệ chữ in hoa cao (\texttt{\_\_FEAT\_HIGH\_CAPS\_\_}), có nhiều ký tự đặc biệt (\texttt{\_\_FEAT\_MANY\_SPECIALS\_\_}) và nhiều chữ số (\texttt{\_\_FEAT\_MANY\_DIGITS\_\_}).
    \item \textbf{Chuẩn hóa văn bản}: Chuyển toàn bộ văn bản về chữ thường, loại bỏ các ký tự không phải chữ và số, và xóa các khoảng trắng thừa.
\end{enumerate}

\begin{minted}{python}
def preprocess_text(text):
    # Trích xuất
    subject = text['Subject']
    message = text['Message']
    
    # Tạo token đặc trưng từ dữ liệu thô
    full_text_raw = str(subject) + " " + str(message)
    # ... (logic tạo feature tokens) ...
    
    # Tiền xử lý văn bản
    processed_text = full_text_raw.lower()
    processed_text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', processed_text)
    processed_text = ' '.join(processed_text.split())
    
    # Kết hợp và trả về
    return feature_token_string + ' ' + processed_text
\end{minted}

\subsection{Tokenization, N-grams và Xây dựng Từ vựng}
Để tăng cường khả năng nhận diện các cụm từ có ý nghĩa, nhóm áp dụng các kỹ thuật sau:
\begin{enumerate}
    \item \textbf{Loại bỏ stopwords}: Các từ phổ biến trong tiếng Anh được loại bỏ.
    \item \textbf{Stemming}: Các từ được đưa về dạng gốc (ví dụ: "running" -> "run").
    \item \textbf{Tạo Bigrams (N=2)}: Các cặp từ liền kề sau khi stemming được kết hợp thành một token duy nhất (ví dụ: "buy\_now") để nắm bắt ngữ cảnh tốt hơn.
    \item \textbf{Xây dựng vocabulary}: Vocabulary được xây dựng từ tập train, chỉ bao gồm các token  unigrams (từ gốc) và bigrams có tần suất xuất hiện >= 3 lần. Kích thước từ vựng cuối cùng là \textbf{301.688} từ.
\end{enumerate}

\section{Mô hình Naive Bayes}

\subsection{Cơ sở lý thuyết}
Naive Bayes là thuật toán phân loại dựa trên định lý Bayes với giả định độc lập có điều kiện giữa các đặc trưng (từ). Công thức phân loại một email:
$$P(y|x) \propto P(y) \prod_{i=1}^{n} P(x_i|y)$$
Trong đó:
\begin{itemize}
    \item $y \in \{spam, ham\}$: nhãn của email.
    \item $x = (x_1, x_2, ..., x_n)$: các từ trong email.
    \item $P(y)$: xác suất tiên nghiệm của lớp $y$.
    \item $P(x|y)$: likelihood của dữ liệu $x$ cho lớp $y$.
\end{itemize}

\subsection{Ước lượng tham số với Laplace Smoothing}
Để tránh vấn đề xác suất bằng 0 khi gặp từ chưa xuất hiện, sử dụng kỹ thuật \texttt{Laplace smoothing}:
$$P(w|y) = \frac{count(w, y) + \alpha}{count(y) + \alpha|V|}$$
Trong đó $|V|$ là kích thước từ vựng và $\alpha$ là tham số smoothing.

\subsection{Cài đặt mô hình}
\begin{minted}{python}
class NaiveBayesClassifier:
    def __init__(self, alpha=1.0, tokenizer=None):
        self.alpha = alpha
        self.tokenizer = tokenizer #... (khởi tạo các biến khác)

    def fit(self, X_train, y_train):
        # ... (tính xác suất tiên nghiệm) ...
        
        # Đếm từ và xây dựng từ vựng
        word_counts = {c: Counter() for c in self.classes}
        all_words_counter = Counter()
        for text, label in zip(X_train, y_train):
            # ... (cập nhật word_counts và all_words_counter) ...
        
        # Cắt tỉa (pruning) để tạo bộ từ vựng cuối cùng
        min_frequency = 3
        self.vocab = {word for word, count 
                      in all_words_counter.items() 
                      if count >= min_frequency}
        
        # ... (tính likelihood với Laplace smoothing) ...
        return self

    def predict(self, X_test):
        # ... (logic dự đoán) ...
        return predictions
\end{minted}

\section{Kết quả thực nghiệm}

\subsection{Đánh giá mô hình}
Mô hình được huấn luyện trên \texttt{train.csv} và đánh giá cả 2 \texttt{train.csv} và \texttt{val.csv}. Với kết quả trong Bảng \ref{tab:results}.

\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Tập dữ liệu} & \textbf{Accuracy} & \textbf{Precision (Spam)} & \textbf{Recall (Spam)} & \textbf{F1-Score (Spam)} \\
\hline
Train set & 99.54\% & 99.54\% & 99.55\% & 99.55\% \\
\hline
Val set & \textbf{98.93\%} & \textbf{98.79\%} & \textbf{99.10\%} & \textbf{98.95\%} \\
\hline
\end{tabular}
\caption{Kết quả đánh giá mô hình Naive Bayes với alpha = 1}
\label{tab:results}
\end{table}

\subsection{Confusion Matrix}
Confusion Matrix trên tập validation cho thấy khả năng phân biệt tốt giữa hai lớp, với rất ít trường hợp dự đoán sai.

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
& \textbf{Dự đoán: Ham} & \textbf{Dự đoán: Spam} \\
\hline
\textbf{Thực tế: Ham} & \textbf{1504} & \textbf{19} \\
\hline
\textbf{Thực tế: Spam} & \textbf{14} & \textbf{1547} \\
\hline
\end{tabular}
\caption{Confusion Matrix trên tập validation (Tổng số: 3.084)}
\label{fig:confusion_matrix}
\end{table}

\section{Thử nghiệm thực tế}

\subsection{Chức năng 1: Dự đoán email đơn lẻ}
Hệ thống cho phép người dùng nhập tiêu đề và nội dung để phân loại.

\begin{minted}{python}
def predict_user_email():
    # ... (nhập subject và message từ người dùng) ...
    
    # Tiền xử lý
    predict_text = preprocess_text({'Subject': subject, 'Message': message})
    
    # Dự đoán và tính xác suất
    prediction, log_probs = nb_classifier._predict_single(predict_text)
    # ... (logic tính và hiển thị xác suất) ...

# Ví dụ sử dụng
subject = "50% offf Iphone 16"
message = "Only for today"
# Kết quả:
# Dự đoán: SPAM
# Xác suất: Spam=95.83%, Ham=4.17%
\end{minted}

\subsection{Chức năng 2: Đánh giá file CSV mới}
Chương trình cung cấp chức năng để người dùng có thể tải lên một file CSV (có cấu trúc tương tự \texttt{val.csv}) và nhận về kết quả đánh giá hiệu suất của mô hình trên file đó.

\section{Phân tích và thảo luận}

\subsection{Các cải tiến}
\begin{itemize}
    \item \textbf{Sử dụng N-grams để nắm bắt ngữ cảnh:} Để khắc phục một phần giả định độc lập giữa các từ, mô hình đã sử dụng \textbf{bigrams} (cặp từ) bên cạnh các từ đơn (unigrams). Điều này giúp mô hình nhận diện được các cụm từ có ý nghĩa như "buy now" hay "limited time", cải thiện độ chính xác khi phân loại.

    \item \textbf{Feature Engineering - Tạo token đặc trưng:} Thay vì chỉ dựa vào nội dung văn bản, mô hình tạo ra các token đặc trưng để nắm bắt đặc điểm quan trọng thường xuất hiện trong thư rác. Các đặc trưng này bao gồm:
    \begin{itemize}
        \item Tỷ lệ chữ IN HOA cao (\texttt{\_\_FEAT\_HIGH\_CAPS\_\_}).
        \item Sự xuất hiện của nhiều ký tự đặc biệt như `!`, `\$`, `\%` (\texttt{\_\_FEAT\_MANY\_SPECIALS\_\_}).
        \item Sự xuất hiện của nhiều chữ số (\texttt{\_\_FEAT\_MANY\_DIGITS\_\_}).
    \end{itemize}
    \item \textbf{Tối ưu hóa tham số Smoothing (Alpha):} Nhóm đã thử nghiệm với các giá trị $\alpha$ khác nhau (0.1, 0.5, 1.0, 2.0, 5.0). Kết quả cho thấy mô hình đạt Accuracy cao nhất trên tập validation khi $\alpha = \textbf{0.5}$ (Accuracy = 0.9870).
\end{itemize}

\subsection{Các hạn chế}
\begin{itemize}
    \item \textbf{Chọn alpha thủ công:} Chọn các mốc alpha thủ công, không tối ưu nhất. Nhóm không sử dụng các phương pháp để chọn alpha tôi ưu vì có các phương pháp tốn quá nhiều thời gian (K-fold, Grid search, ...) và các phương pháp quá phức tạp vượt qua phạm vi môn học (Bayesian Optimization, ...)
    \item \textbf{Feature Engineering:} Có thể cải tiến bằng cách thêm các đặc trưng khác như nguồn gốc email, sự tồn tại của tệp đính kèm, hoặc phân tích sâu hơn về cấu trúc HTML của email. Hiện tại bỏ qua vì kết quả đã rất tốt và cách này cũng khá phức tạp để triển khai.
\end{itemize}

\section{Kết luận}
 Nhóm đã xây dựng mô hình phân loại thư rác hiệu quả bằng thuật toán Naive Bayes. Mô hình đạt Accuracy tốt là \textbf{98.93\%} trên tập Val, cho thấy khả năng tổng quát hóa tốt.

Các đóng điểm chính của bài lab:
\begin{itemize}
    \item Cài đặt thuật toán Naive Bayes "from-scratch"
    \item Áp dụng các kỹ thuật tiền xử lý và feature engineering (bigrams, token đặc trưng) để nâng cao hiệu suất.
    \item Xây dựng các 2 chức năng như yêu cầu đề bài để người dùng có thể tương tác và đánh giá trên tập dữ liệu mới.
\end{itemize}