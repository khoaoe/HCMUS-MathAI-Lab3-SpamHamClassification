{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2p4uuBsaHNn"
      },
      "source": [
        "# Lab 3 - Phân loại thư rác với Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7kBbpD7aHNp"
      },
      "source": [
        "## Thông tin nhóm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeMjqEXvaHNp"
      },
      "source": [
        "## 1. Import thư viện và tải dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c9hEDCsa20L",
        "outputId": "5b0dff76-f032-4341-c72e-2ff2660bcd40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã import các thư viện.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import Counter, defaultdict\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Đã import các thư viện.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKIyOWokl6pu",
        "outputId": "4565cc8d-4297-459f-b6c8-ff818a5c3dfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã tải và sẵn sàng sử dụng stopwords.\n"
          ]
        }
      ],
      "source": [
        "# Lấy danh sách stop words\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer # <<< THÊM DÒNG NÀY\n",
        "\n",
        "try:\n",
        "    # Thử tìm tài nguyên stopwords\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    # Nếu không tìm thấy (gây ra LookupError), thì mới tải về\n",
        "    print(\"Tài nguyên stopwords chưa được tải, đang tiến hành tải...\")\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "# Tải thêm tài nguyên 'punkt' nếu cần\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    print(\"Tài nguyên punkt chưa được tải, đang tiến hành tải...\")\n",
        "    nltk.download('punkt') # <<< THÊM KHỐI NÀY\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "print(\"Đã tải và sẵn sàng sử dụng stopwords.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "LdEQ47baaHNq",
        "outputId": "91750a9e-0239-422c-e286-6785db88eff3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đang tải dữ liệu...\n",
            "Kích thước tập train: (27284, 6)\n",
            "Kích thước tập validation: (3084, 6)\n",
            "\n",
            "5 dòng đầu tiên của tập train:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Message ID                       Subject  \\\n",
              "0           0           0  christmas tree farm pictures   \n",
              "1           1           1      vastar resources , inc .   \n",
              "2           2           2  calpine daily gas nomination   \n",
              "3           3           3                    re : issue   \n",
              "4           5           5      mcmullen gas for 11 / 99   \n",
              "\n",
              "                                             Message Spam/Ham     split  \n",
              "0                                                NaN      ham  0.038415  \n",
              "1  gary , production from the high island larger ...      ham  0.696509  \n",
              "2             - calpine daily gas nomination 1 . doc      ham  0.587792  \n",
              "3  fyi - see note below - already done .\\nstella\\...      ham -0.055438  \n",
              "4  jackie ,\\nsince the inlet to 3 river plant is ...      ham -0.419658  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c7d96499-d38e-4bed-91ed-431b61411371\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Message ID</th>\n",
              "      <th>Subject</th>\n",
              "      <th>Message</th>\n",
              "      <th>Spam/Ham</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>christmas tree farm pictures</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ham</td>\n",
              "      <td>0.038415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>vastar resources , inc .</td>\n",
              "      <td>gary , production from the high island larger ...</td>\n",
              "      <td>ham</td>\n",
              "      <td>0.696509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>calpine daily gas nomination</td>\n",
              "      <td>- calpine daily gas nomination 1 . doc</td>\n",
              "      <td>ham</td>\n",
              "      <td>0.587792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>re : issue</td>\n",
              "      <td>fyi - see note below - already done .\\nstella\\...</td>\n",
              "      <td>ham</td>\n",
              "      <td>-0.055438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>mcmullen gas for 11 / 99</td>\n",
              "      <td>jackie ,\\nsince the inlet to 3 river plant is ...</td>\n",
              "      <td>ham</td>\n",
              "      <td>-0.419658</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7d96499-d38e-4bed-91ed-431b61411371')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c7d96499-d38e-4bed-91ed-431b61411371 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c7d96499-d38e-4bed-91ed-431b61411371');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9213eb96-7b3c-4834-81eb-cb62de44e271\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9213eb96-7b3c-4834-81eb-cb62de44e271')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9213eb96-7b3c-4834-81eb-cb62de44e271 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 27284,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9724,\n        \"min\": 0,\n        \"max\": 33715,\n        \"num_unique_values\": 27284,\n        \"samples\": [\n          5123,\n          12402,\n          12979\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Message ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9724,\n        \"min\": 0,\n        \"max\": 33715,\n        \"num_unique_values\": 27284,\n        \"samples\": [\n          5123,\n          12402,\n          12979\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subject\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20231,\n        \"samples\": [\n          \"investment idea\",\n          \"paracodin sells better than vicodin\",\n          \"for the last three decades , brokerage houses - - such as merryll lynch - - have cashed in with greater returns than any other industry\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24451,\n        \"samples\": [\n          \"hows it been going ?\\nyou have been chosen to participate in an invitation\\nonly event !\\nare you currently paying over 3 % for your mortgage ?\\nstop ! we can help you lower that today !\\nanswer only a few questions and we can get you\\napproved in under 1 minute , it ' s that simple !\\nmore info here : anyhgh . com\\n$ 302 , 000 loans are available for only $ 231 / month !\\neveryone is approved !\\nbad credit ?\\nno problem ! we ' ll have you saving money in no time !\\nare you ready to save ?\\njust fill out our short form : anyhgh . com\\nthanks alot ,\\nbaez v . jodie , v\\nprojecthoneypot @ projecthoneypot . org\\nthe secret of life is honesty and fair dealing . if you can fake that , you ' ve got it made . - groucho marx ( 1890 - 1977 ) . from that day on there were new rules in my classroom . each student was to have an adult ' communication partner ' at the computer . this adult was to sit with the child , not saying a word until the student stopped and looked at the adult or in some other way indicated that communication was desired . then the adult was only to encourage the student by saying the word , nodding the headand smiling . the student was allowed to continue his or her learning . when the student imitated a word , the adult was to respond appropriately . no questions were allowed during this beginning phase . the students were just learning to talk . .\\nluke is missing jumping today . . few things are harder to put up with than the annoyance of a good example . .\\nall my life i ' ve wanted to be someone ; i guess i should have been more specific . jane wagner / lily tomlin ( 1939 - ) . i am not missing surfing . .\",\n          \"discount drugs . . . save 80 % every order !\\nwe are the number one online retailler for dozens of medications . our customers save 80\\ncents out of every dollar , every time , compared to the industry price . yes , that is less than\\nquarter - price\\nwe have all the products that our customers have asked for , including new superviagra\\nsoft - tabs that work in just 15 minutes ! this is the next - generation of sexual improvement\\nwonder - drugs , far more effective than viagra - half a pill will last for 36 hours !\\nget all the information on superviagra here : http : / / friggings . net / cs / ? cheapgeneric\\nour key to keeping customers satisfied is :\\neasy ordering online\\nsave 80 % on regular price\\nwe have massive stocks of drugs for same day dispatch\\nfast delivery straight to your door with discrete packaging\\nwe are the biggest internet retailler with thousands of regular customers\\nno consultation fee\\nno intimate questions or examinations\\nno appointment\\nno prior prescription needed\\nprivate and confidential service\\nplease come by our shop , see for yourself the massive range of products that we have\\navailable . we do have the lowest price and huge stocks ready for same - day dispatch .\\ntwo million customers can ' t be wrong !\\nsee our full range at http : / / friggings . net / ? cheapgeneric\\n\",\n          \"per my voicemails to each of you . . . .\\njenny latham is currently a manager in power risk in houston , and is\\ninterested in moving to london . she is very well respected within enron , and\\nis a highly rated employee . she has been with enron for several years , in\\nvarious positions , and will move us far ahead in the staffing . in january , i\\nmet with yvonne scorer to identify recruiting needs to build the mid and back\\noffice for the london activity for eim . one position identified , business\\ncontroller , is the position i have discussed with jenny , and she is very\\ninterested . i am anxious to move this forward asap for a couple of reasons :\\n1 ) . jenny is interested , and i do not want to lose her to other\\nopportunities within the london office , and 2 ) . it is not too early to move\\nforward on the staffing of the office as it will take some time to\\nappropriately staff and transition current support from egm .\\nbruce , last week jenny and i met with you , and we discussed that it would be\\nappropriate for jenny to spend time with us here in houston to learn our\\ncurrent processes , commoditiies , etc . i absolutely agree with this , but we\\nneed to make a deal with her before we can start that process . the sequence\\nof events that make sense to me and that i believe would make jenny the most\\ncomfortable is that we 1 ) . agree on the financial package ( compensation ,\\nmoving allowance , etc ) , 2 ) . transition her current responsibilities within\\npower risk , and 3 ) . begin training with us . simultaneously , we will need to\\nrecruit applicants for the remaining positions in risk , documentation ,\\nsettlements and trade accounting . my goal is to have everything in place in\\nlondon by the end of first quarter .\\nto meet this time line , we need to get more information and have a discussion\\nwith meryl on the specifics . bruce , can you give meryl the green light to\\nmove forward with us ? i appreciate your help .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spam/Ham\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0024066869151718,\n        \"min\": -3.842532500480177,\n        \"max\": 3.6127381957087294,\n        \"num_unique_values\": 27284,\n        \"samples\": [\n          0.9783164143218958,\n          -1.0624398833040851\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Đọc dữ liệu\n",
        "print(\"Đang tải dữ liệu...\")\n",
        "train_data = pd.read_csv('train.csv',  on_bad_lines='skip', engine='python')\n",
        "val_data = pd.read_csv('val.csv',  on_bad_lines='skip', engine='python')\n",
        "\n",
        "print(f\"Kích thước tập train: {train_data.shape}\")\n",
        "print(f\"Kích thước tập validation: {val_data.shape}\")\n",
        "print(\"\\n5 dòng đầu tiên của tập train:\")\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x-UGbDeaHNs"
      },
      "source": [
        "## 2. Tiền xử lý dữ liệu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM-cQTdjaHNs"
      },
      "source": [
        "### 2.1 Kiểm tra và làm sạch dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anzj8tzkaHNt",
        "outputId": "d3d2cc2a-6205-4a93-deb1-088af1f6c0a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kiểm tra dữ liệu null:\n",
            "Unnamed: 0      0\n",
            "Message ID      0\n",
            "Subject       229\n",
            "Message       352\n",
            "Spam/Ham        0\n",
            "split           0\n",
            "dtype: int64\n",
            "\n",
            "Kiểm tra dữ liệu null trong val set:\n",
            "Unnamed: 0     0\n",
            "Message ID     0\n",
            "Subject       29\n",
            "Message       35\n",
            "Spam/Ham       0\n",
            "split          0\n",
            "dtype: int64\n",
            "\n",
            "Số dòng trùng lặp trong train: 0\n",
            "Số dòng trùng lặp trong val: 0\n",
            "\n",
            "Phân phối nhãn trong tập train:\n",
            "Spam/Ham\n",
            "spam    13858\n",
            "ham     13426\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Phân phối nhãn trong tập val:\n",
            "Spam/Ham\n",
            "spam    1563\n",
            "ham     1521\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Kiểm tra dữ liệu null\n",
        "print(\"Kiểm tra dữ liệu null:\")\n",
        "print(train_data.isnull().sum())\n",
        "print(\"\\nKiểm tra dữ liệu null trong val set:\")\n",
        "print(val_data.isnull().sum())\n",
        "\n",
        "# Điền giá trị rỗng cho Message nếu có\n",
        "train_data['Message'] = train_data['Message'].fillna('')\n",
        "val_data['Message'] = val_data['Message'].fillna('')\n",
        "\n",
        "# Kiểm tra dữ liệu trùng lặp\n",
        "print(f\"\\nSố dòng trùng lặp trong train: {train_data.duplicated().sum()}\")\n",
        "print(f\"Số dòng trùng lặp trong val: {val_data.duplicated().sum()}\")\n",
        "\n",
        "# Loại bỏ dòng trùng lặp nếu có\n",
        "train_data = train_data.drop_duplicates().reset_index(drop=True)\n",
        "val_data = val_data.drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "# Kiểm tra phân phối nhãn\n",
        "print(\"\\nPhân phối nhãn trong tập train:\")\n",
        "print(train_data['Spam/Ham'].value_counts())\n",
        "print(\"\\nPhân phối nhãn trong tập val:\")\n",
        "print(val_data['Spam/Ham'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JF7xkUvaHNu"
      },
      "source": [
        "### 2.2 Tiền xử lý văn bản"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3Ddz_xSaHNv"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Tiền xử lý văn bản:\n",
        "    - Chuyển về chữ thường\n",
        "    - Loại bỏ ký tự đặc biệt, giữ lại chữ và số\n",
        "    - Loại bỏ khoảng trắng thừa\n",
        "    \"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "\n",
        "    # Chuyển về chữ thường\n",
        "    text = text.lower()\n",
        "\n",
        "    # Loại bỏ các ký tự đặc biệt, giữ lại chữ, số và khoảng trắng\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
        "\n",
        "    # Loại bỏ khoảng trắng thừa\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Áp dụng tiền xử lý cho dữ liệu\n",
        "print(\"Đang tiền xử lý văn bản...\")\n",
        "train_data['processed_subject'] = train_data['Subject'].apply(preprocess_text)\n",
        "train_data['processed_message'] = train_data['Message'].apply(preprocess_text)\n",
        "train_data['combined_text'] = train_data['processed_subject'] + ' ' + train_data['processed_message']\n",
        "\n",
        "val_data['processed_subject'] = val_data['Subject'].apply(preprocess_text)\n",
        "val_data['processed_message'] = val_data['Message'].apply(preprocess_text)\n",
        "val_data['combined_text'] = val_data['processed_subject'] + ' ' + val_data['processed_message']\n",
        "\n",
        "print(\"Ví dụ văn bản sau khi tiền xử lý:\")\n",
        "print(train_data[['Subject', 'processed_subject']].head(3))"
      ],
      "metadata": {
        "id": "jQ-CcVf0v3SO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50a257ed-b1bc-4837-b6c3-10e2d2141fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đang tiền xử lý văn bản...\n",
            "Ví dụ văn bản sau khi tiền xử lý:\n",
            "                        Subject             processed_subject\n",
            "0  christmas tree farm pictures  christmas tree farm pictures\n",
            "1      vastar resources , inc .          vastar resources inc\n",
            "2  calpine daily gas nomination  calpine daily gas nomination\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0epgOuNeaHNv"
      },
      "source": [
        "## 3. Xây dựng mô hình Naive Bayes từ đầu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anyhuTf0aHNw"
      },
      "source": [
        "### 3.1 Lý thuyết Naive Bayes\n",
        "\n",
        "Naive Bayes Classifier cho phân loại văn bản:\n",
        "\n",
        "1. Theo Bayes' theorem:\n",
        "   P(class|document) = P(document|class) * P(class) / P(document)\n",
        "\n",
        "2. Với giả định Naive Bayes (độc lập có điều kiện):\n",
        "   P(document|class) = P(word1|class) * P(word2|class) * ... * P(wordn|class)\n",
        "\n",
        "3. Sử dụng log probability để tránh underflow:\n",
        "   log P(class|document) = log P(class) + Σ log P(word|class)\n",
        "\n",
        "4. Laplace smoothing để xử lý từ chưa xuất hiện:\n",
        "   P(word|class) = (count(word, class) + α) / (count(all words in class) + α * |V|)\n",
        "   với α = 1 (Laplace smoothing), |V| là kích thước từ vựng"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quy trình của hàm 'tokenizer_with_bigrams':\n",
        "\n",
        "  - Tách từ và loại bỏ stop words: Tách văn bản thành các từ và loại bỏ những từ phổ biến, không mang nhiều ý nghĩa.\n",
        "\n",
        "  - Stemming: Đưa các từ về dạng gốc (ví dụ running -> run).\n",
        "\n",
        "  - Tạo Bigrams: Ghép mỗi cặp từ liền kề (đã được stem) thành một token duy nhất (ví dụ buy_now).\n",
        "\n",
        "Kết quả: Trả về một danh sách bao gồm cả các từ đơn và các cặp từ đã được xử lý."
      ],
      "metadata": {
        "id": "QFVsrmS88Zgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize + bigrams\n",
        "def tokenizer_with_bigrams(text, stop_words_set, stemmer):\n",
        "    \"\"\"\n",
        "    Hàm tokenizer,  tạo unigrams và bigrams.\n",
        "    \"\"\"\n",
        "    # Tokenize và loại bỏ stop words\n",
        "    words = text.split()\n",
        "    unigrams = [word for word in words if word not in stop_words_set]\n",
        "\n",
        "    # Stemming\n",
        "    stemmed_unigrams = [stemmer.stem(word) for word in unigrams]\n",
        "\n",
        "    # Tạo bigrams từ các từ đã stem\n",
        "    bigrams = ['_'.join(pair) for pair in zip(stemmed_unigrams, stemmed_unigrams[1:])]\n",
        "\n",
        "    return stemmed_unigrams + bigrams"
      ],
      "metadata": {
        "id": "O2NlYV-lx1fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f41Ir4vRaHNw"
      },
      "source": [
        "### 3.2 Cài đặt Naive Bayes Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVa9Aef1aHNx"
      },
      "outputs": [],
      "source": [
        "class NaiveBayesClassifier:\n",
        "    def __init__(self, alpha=1.0, tokenizer=None):\n",
        "        \"\"\"\n",
        "        Khởi tạo Naive Bayes Classifier\n",
        "\n",
        "        Parameters:\n",
        "        - alpha: Tham số smoothing (mặc định = 1.0 cho Laplace smoothing)\n",
        "        - tokenizer: Hàm tokenizer, mặc định là _default_tokenize (tokenize và loại bỏ stopword)\n",
        "        \"\"\"\n",
        "        self.alpha = alpha\n",
        "        self.class_priors = {}\n",
        "        self.word_probs = {}\n",
        "        self.classes = []\n",
        "        self.vocab = set()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.stemmer = PorterStemmer()\n",
        "\n",
        "        if tokenizer:\n",
        "            self.tokenizer = lambda text: tokenizer(text, self.stop_words, self.stemmer)\n",
        "        else:\n",
        "            self.tokenizer = self._default_tokenize\n",
        "\n",
        "    def _default_tokenize(self, text):\n",
        "        \"\"\" Tách văn bản thành các từ, loại bỏ stop words và stemming \"\"\"\n",
        "        words = text.split()\n",
        "        words = [word for word in words if word not in self.stop_words]\n",
        "        words = [self.stemmer.stem(word) for word in words]\n",
        "        return words\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        Huấn luyện mô hình Naive Bayes (ĐÃ SỬA LỖI PRUNING)\n",
        "\n",
        "        Parameters:\n",
        "        - X_train: Danh sách văn bản đã tiền xử lý\n",
        "        - y_train: Nhãn tương ứng\n",
        "        \"\"\"\n",
        "        # Lấy danh sách các lớp\n",
        "        self.classes = list(set(y_train))\n",
        "        n_docs = len(y_train)\n",
        "\n",
        "        # Tính prior probability cho mỗi lớp\n",
        "        print(\"Tính prior probability...\")\n",
        "        for c in self.classes:\n",
        "            self.class_priors[c] = sum(1 for y in y_train if y == c) / n_docs\n",
        "            print(f\"P({c}) = {self.class_priors[c]:.4f}\")\n",
        "\n",
        "\n",
        "        # 1. Đếm tất cả các từ trong tập train trước\n",
        "        print(\"\\nĐang đếm từ để xây dựng từ vựng...\")\n",
        "        word_counts = {c: Counter() for c in self.classes}\n",
        "        all_words_counter = Counter()\n",
        "\n",
        "        for text, label in zip(X_train, y_train):\n",
        "            words = self.tokenizer(text)\n",
        "            word_counts[label].update(words)\n",
        "            all_words_counter.update(words)\n",
        "\n",
        "        # 2. Cắt tỉa (pruning) để tạo bộ từ vựng cuối cùng\n",
        "        min_frequency = 3\n",
        "        self.vocab = {word for word, count in all_words_counter.items() if count >= min_frequency}\n",
        "        vocab_size = len(self.vocab)\n",
        "        print(f\"Tổng số từ duy nhất ban đầu: {len(all_words_counter)}\")\n",
        "        print(f\"Kích thước từ vựng sau khi lọc (xuất hiện >= {min_frequency} lần): {vocab_size}\")\n",
        "\n",
        "        # 3. Tính likelihood với Laplace smoothing dựa trên từ vựng đã lọc\n",
        "        print(\"\\nTính likelihood với Laplace smoothing...\")\n",
        "        self.word_probs = {c: {} for c in self.classes}\n",
        "\n",
        "        for c in self.classes:\n",
        "            # Lấy tổng số từ của lớp c (chỉ tính các từ trong vocab)\n",
        "            total_words_in_class = sum(word_counts[c][word] for word in self.vocab)\n",
        "            print(f\"\\nLớp {c}: {total_words_in_class} từ (trong vocab)\")\n",
        "\n",
        "            # Tính P(word|class) cho mỗi từ trong vocabulary\n",
        "            for word in self.vocab:\n",
        "                count = word_counts[c].get(word, 0)\n",
        "                self.word_probs[c][word] = (count + self.alpha) / (total_words_in_class + self.alpha * vocab_size)\n",
        "\n",
        "            # Xác suất cho từ chưa từng xuất hiện (unknown words)\n",
        "            self.word_probs[c]['<UNK>'] = self.alpha / (total_words_in_class + self.alpha * vocab_size)\n",
        "\n",
        "        print(\"\\nHuấn luyện hoàn tất!\")\n",
        "        return self\n",
        "\n",
        "    def _predict_single(self, text):\n",
        "        \"\"\"\n",
        "        Dự đoán nhãn cho một văn bản\n",
        "        Returns: (predicted_class, log_probabilities)\n",
        "        \"\"\"\n",
        "        words = self.tokenizer(text) # Tokenize và stem\n",
        "\n",
        "        log_probs = {}\n",
        "        for c in self.classes:\n",
        "            log_prob = math.log(self.class_priors[c])\n",
        "            for word in words:\n",
        "                # Nếu từ có trong dict xác suất của lớp c\n",
        "                if word in self.word_probs[c]:\n",
        "                    log_prob += math.log(self.word_probs[c][word])\n",
        "                else:\n",
        "                    # Từ không có trong vocab (đã bị lọc) hoặc mới, dùng xác suất UNK\n",
        "                    log_prob += math.log(self.word_probs[c]['<UNK>'])\n",
        "            log_probs[c] = log_prob\n",
        "\n",
        "        predicted_class = max(log_probs, key=log_probs.get)\n",
        "        return predicted_class, log_probs\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        \"\"\"Dự đoán nhãn cho tập văn bản\"\"\"\n",
        "        predictions = []\n",
        "        for text in X_test:\n",
        "            pred, _ = self._predict_single(text)\n",
        "            predictions.append(pred)\n",
        "        return predictions\n",
        "\n",
        "    # Hàm predict_proba không thay đổi\n",
        "    def predict_proba(self, X_test):\n",
        "        proba_list = []\n",
        "        for text in X_test:\n",
        "            _, log_probs = self._predict_single(text)\n",
        "            max_log_prob = max(log_probs.values())\n",
        "            exp_probs = {c: math.exp(log_prob - max_log_prob) for c, log_prob in log_probs.items()}\n",
        "            total = sum(exp_probs.values())\n",
        "            probs = {c: exp_prob / total for c, exp_prob in exp_probs.items()}\n",
        "            proba_list.append(probs)\n",
        "        return proba_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7BEpwyGaHNx"
      },
      "source": [
        "### 3.3 Huấn luyện mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjBQVCacaHNy"
      },
      "outputs": [],
      "source": [
        "# Khởi tạo và huấn luyện mô hình\n",
        "nb_classifier = NaiveBayesClassifier(alpha=1, tokenizer=tokenizer_with_bigrams)\n",
        "\n",
        "# Chuẩn bị dữ liệu\n",
        "X_train = train_data['combined_text'].values\n",
        "y_train = train_data['Spam/Ham'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6cU8P41fGq7",
        "outputId": "7a9058c8-f1e7-473f-8152-dee495fbf15c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bắt đầu huấn luyện mô hình...\n",
            "Tính prior probability...\n",
            "P(spam) = 0.5079\n",
            "P(ham) = 0.4921\n",
            "\n",
            "Đang đếm từ để xây dựng từ vựng...\n",
            "Tổng số từ duy nhất ban đầu: 1343331\n",
            "Kích thước từ vựng sau khi lọc (xuất hiện >= 3 lần): 300431\n",
            "\n",
            "Tính likelihood với Laplace smoothing...\n",
            "\n",
            "Lớp spam: 3098034 từ (trong vocab)\n",
            "\n",
            "Lớp ham: 3396182 từ (trong vocab)\n",
            "\n",
            "Huấn luyện hoàn tất!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.NaiveBayesClassifier at 0x78c3bb380d90>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "print(\"Bắt đầu huấn luyện mô hình...\")\n",
        "nb_classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95dWxvj8aHNy"
      },
      "source": [
        "### 3.4 Đánh giá mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwddYPCaaHNy"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Đánh giá mô hình với các metrics:\n",
        "    - Accuracy\n",
        "    - Precision, Recall, F1-score cho mỗi lớp\n",
        "    - Confusion Matrix\n",
        "    \"\"\"\n",
        "\n",
        "    # Accuracy\n",
        "    accuracy = sum(y_t == y_p for y_t, y_p in zip(y_true, y_pred)) / len(y_true)\n",
        "\n",
        "    # Confusion Matrix và metrics cho mỗi lớp\n",
        "    classes = list(set(y_true))\n",
        "    metrics = {}\n",
        "\n",
        "    for c in classes:\n",
        "        # True Positive, False Positive, False Negative, True Negative\n",
        "        tp = sum((y_t == c) and (y_p == c) for y_t, y_p in zip(y_true, y_pred))\n",
        "        fp = sum((y_t != c) and (y_p == c) for y_t, y_p in zip(y_true, y_pred))\n",
        "        fn = sum((y_t == c) and (y_p != c) for y_t, y_p in zip(y_true, y_pred))\n",
        "        tn = sum((y_t != c) and (y_p != c) for y_t, y_p in zip(y_true, y_pred))\n",
        "\n",
        "        # Precision, Recall, F1\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        metrics[c] = {\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1,\n",
        "            'tp': tp, 'fp': fp, 'fn': fn, 'tn': tn\n",
        "        }\n",
        "\n",
        "    return accuracy, metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdcZFi_1fCSp",
        "outputId": "71721f48-2704-4d8d-b62f-4fabb7177b34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đánh giá trên tập train:\n",
            "Accuracy: 0.9947\n",
            "\n",
            "Lớp 'spam':\n",
            "  Precision: 0.9944\n",
            "  Recall: 0.9952\n",
            "  F1-score: 0.9948\n",
            "\n",
            "Lớp 'ham':\n",
            "  Precision: 0.9950\n",
            "  Recall: 0.9942\n",
            "  F1-score: 0.9946\n",
            "\n",
            "Confusion Matrix:\n",
            "             Predicted ↓\n",
            "Actual ↓    spam    ham\n",
            "spam       13791      67\n",
            "ham           78   13348\n",
            "\n",
            "==================================================\n",
            "Đánh giá trên tập validation:\n",
            "Accuracy: 0.9887\n",
            "\n",
            "Lớp 'spam':\n",
            "  Precision: 0.9872\n",
            "  Recall: 0.9904\n",
            "  F1-score: 0.9888\n",
            "\n",
            "Lớp 'ham':\n",
            "  Precision: 0.9901\n",
            "  Recall: 0.9869\n",
            "  F1-score: 0.9885\n",
            "\n",
            "Confusion Matrix:\n",
            "             Predicted ↓\n",
            "Actual ↓    spam    ham\n",
            "spam        1548      15\n",
            "ham           20    1501\n"
          ]
        }
      ],
      "source": [
        "# Đánh giá trên tập train\n",
        "print(\"Đánh giá trên tập train:\")\n",
        "train_predictions = nb_classifier.predict(X_train)\n",
        "train_accuracy, train_metrics = evaluate_model(y_train, train_predictions)\n",
        "\n",
        "print(f\"Accuracy: {train_accuracy:.4f}\")\n",
        "for c in train_metrics:\n",
        "    m = train_metrics[c]\n",
        "    print(f\"\\nLớp '{c}':\")\n",
        "    print(f\"  Precision: {m['precision']:.4f}\")\n",
        "    print(f\"  Recall: {m['recall']:.4f}\")\n",
        "    print(f\"  F1-score: {m['f1']:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(\"             Predicted ↓\")\n",
        "print(\"Actual ↓    spam    ham\")\n",
        "for true_class in ['spam', 'ham']:\n",
        "    print(f\"{true_class:8s}\", end=\"\")\n",
        "    for pred_class in ['spam', 'ham']:\n",
        "        count = sum((y_t == true_class) and (y_p == pred_class)\n",
        "                   for y_t, y_p in zip(y_train, train_predictions))\n",
        "        print(f\"{count:8d}\", end=\"\")\n",
        "    print()\n",
        "\n",
        "# Đánh giá trên tập validation\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Đánh giá trên tập validation:\")\n",
        "X_val = val_data['combined_text'].values\n",
        "y_val = val_data['Spam/Ham'].values\n",
        "\n",
        "val_predictions = nb_classifier.predict(X_val)\n",
        "val_accuracy, val_metrics = evaluate_model(y_val, val_predictions)\n",
        "\n",
        "print(f\"Accuracy: {val_accuracy:.4f}\")\n",
        "for c in val_metrics:\n",
        "    m = val_metrics[c]\n",
        "    print(f\"\\nLớp '{c}':\")\n",
        "    print(f\"  Precision: {m['precision']:.4f}\")\n",
        "    print(f\"  Recall: {m['recall']:.4f}\")\n",
        "    print(f\"  F1-score: {m['f1']:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(\"             Predicted ↓\")\n",
        "print(\"Actual ↓    spam    ham\")\n",
        "for true_class in ['spam', 'ham']:\n",
        "    print(f\"{true_class:8s}\", end=\"\")\n",
        "    for pred_class in ['spam', 'ham']:\n",
        "        count = sum((y_t == true_class) and (y_p == pred_class)\n",
        "                   for y_t, y_p in zip(y_val, val_predictions))\n",
        "        print(f\"{count:8d}\", end=\"\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.5 Phân tích các dự đoán sai"
      ],
      "metadata": {
        "id": "_cFaH9vgrwoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_errors(y_true, y_pred, data):\n",
        "    print(\"=== PHÂN TÍCH LỖI ===\")\n",
        "    # In ra 5 email ham bị đoán nhầm là spam (False Positives)\n",
        "    fp_indices = [i for i, (true, pred) in enumerate(zip(y_true, y_pred)) if true == 'ham' and pred == 'spam']\n",
        "    print(f\"\\n--- {len(fp_indices)} False Positives (Ham -> Spam) ---\")\n",
        "    for i in fp_indices[:5]:\n",
        "        print(f\"Email {i}:\")\n",
        "        print(f\"  Subject: \\\"{data.iloc[i]['Subject']}\\\"\")\n",
        "        print(f\"  Message: \\\"{str(data.iloc[i]['Message'])[:50]}...\\\"\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # In ra 5 email spam bị đoán nhầm là ham (False Negatives)\n",
        "    fn_indices = [i for i, (true, pred) in enumerate(zip(y_true, y_pred)) if true == 'spam' and pred == 'ham']\n",
        "    print(f\"\\n--- {len(fn_indices)} False Negatives (Spam -> Ham) ---\")\n",
        "    for i in fn_indices[:5]:\n",
        "        print(f\"Email {i}:\")\n",
        "        print(f\"  Subject: \\\"{data.iloc[i]['Subject']}\\\"\")\n",
        "        print(f\"  Message: \\\"{str(data.iloc[i]['Message'])[:50]}...\\\"\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "2PZOLmEjr2_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_errors(y_val, val_predictions, val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GuH7eFcr-Ks",
        "outputId": "9562b208-10e7-4be3-decc-6b17b43a96ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PHÂN TÍCH LỖI ===\n",
            "\n",
            "--- 20 False Positives (Ham -> Spam) ---\n",
            "Email 18:\n",
            "  Subject: \"tech - support @ service . juno . com : problems retrieving mail\"\n",
            "  Message: \"daren i guess i need help with this too ! love you...\"\n",
            "Email 26:\n",
            "  Subject: \"valentines day help\"\n",
            "  Message: \"red - neck valentine ' s love poem\n",
            "collards is gre...\"\n",
            "Email 48:\n",
            "  Subject: \"wassup - south park\"\n",
            "  Message: \"- wassupsouthparkl . exe...\"\n",
            "Email 58:\n",
            "  Subject: \"registration confirmation - my yahoo !\"\n",
            "  Message: \"account information\n",
            "help\n",
            "do not reply to this mess...\"\n",
            "Email 276:\n",
            "  Subject: \"please note my new email address\"\n",
            "  Message: \"effective today , please send future correspondenc...\"\n",
            "--------------------------------------------------\n",
            "\n",
            "--- 15 False Negatives (Spam -> Ham) ---\n",
            "Email 357:\n",
            "  Subject: \"re : no more injections\"\n",
            "  Message: \"...\"\n",
            "Email 1519:\n",
            "  Subject: \"peter g [ tour dates ]\"\n",
            "  Message: \"tour dates\n",
            "friday 8 th - regua open air\n",
            "saturday 9...\"\n",
            "Email 1804:\n",
            "  Subject: \"all alone ? need somoene to talk to ?\"\n",
            "  Message: \"...\"\n",
            "Email 1908:\n",
            "  Subject: \"re : invitation for review a paper for the ieee trans . neural networks\"\n",
            "  Message: \"giorgo\n",
            "efxaristo pou apodektikes .\n",
            "an thes , kane ...\"\n",
            "Email 1953:\n",
            "  Subject: \"the original\"\n",
            "  Message: \"autumn told me that you were drowing in deebbbt .\n",
            "...\"\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KC-DdpUaHNz"
      },
      "source": [
        "## 4. Thử nghiệm thực tế"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz8ILhBaaHNz"
      },
      "source": [
        "### 4.1 Chức năng 1: Dự đoán email người dùng nhập"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xo17wHEaHNz"
      },
      "outputs": [],
      "source": [
        "def predict_user_email():\n",
        "    \"\"\"\n",
        "    Cho phép người dùng nhập email và dự đoán spam/ham\n",
        "    \"\"\"\n",
        "    print(\"=== DỰ ĐOÁN EMAIL ===\")\n",
        "    subject = input(\"Nhập tiêu đề email: \")\n",
        "    message = input(\"Nhập nội dung email: \")\n",
        "\n",
        "    # Tiền xử lý\n",
        "    processed_subject = preprocess_text(subject)\n",
        "    processed_message = preprocess_text(message)\n",
        "    combined = processed_subject + ' ' + processed_message\n",
        "\n",
        "    # Dự đoán\n",
        "    prediction, log_probs = nb_classifier._predict_single(combined)\n",
        "\n",
        "    # Tính xác suất\n",
        "    max_log_prob = max(log_probs.values())\n",
        "    exp_probs = {c: math.exp(log_prob - max_log_prob)\n",
        "                for c, log_prob in log_probs.items()}\n",
        "    total = sum(exp_probs.values())\n",
        "    probs = {c: exp_prob / total for c, exp_prob in exp_probs.items()}\n",
        "\n",
        "    print(f\"\\nKết quả dự đoán: {prediction.upper()}\")\n",
        "    print(f\"Xác suất spam: {probs['spam']:.4f}\")\n",
        "    print(f\"Xác suất ham: {probs['ham']:.4f}\")\n",
        "\n",
        "    return prediction, probs"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 71,
=======
      "execution_count": null,
>>>>>>> bbf3d567caf841d1d4dd89cf2975199db9674a92
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Uc5-mllaHN0",
        "outputId": "4df5371d-b37a-4ef8-a527-1736bf204c9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== DỰ ĐOÁN EMAIL ===\n",
            "Nhập tiêu đề email: sigmasigmasigmasimga\n",
            "Nhập nội dung email: abcdefghijklmnop\n",
            "\n",
            "Kết quả dự đoán: SPAM\n",
            "Xác suất spam: 0.5732\n",
            "Xác suất ham: 0.4268\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('spam', {'spam': 0.5732485783295769, 'ham': 0.426751421670423})"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "# Test chức năng\n",
        "predict_user_email()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73b3ld3VaHN0"
      },
      "source": [
        "### 4.2 Chức năng 2: Đánh giá file CSV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuExLxrfaHN0"
      },
      "outputs": [],
      "source": [
        "def evaluate_csv_file(filename):\n",
        "    \"\"\"\n",
        "    Đọc và đánh giá mô hình trên file CSV\n",
        "    File CSV cần có cấu trúc giống val.csv\n",
        "    \"\"\"\n",
        "    print(f\"=== ĐÁNH GIÁ FILE: {filename} ===\")\n",
        "\n",
        "    try:\n",
        "        # Đọc file\n",
        "        data = pd.read_csv(filename)\n",
        "        print(f\"Đã đọc {len(data)} dòng từ file\")\n",
        "\n",
        "        # Kiểm tra cấu trúc\n",
        "        required_cols = ['Subject', 'Message', 'Spam/Ham']\n",
        "        if not all(col in data.columns for col in required_cols):\n",
        "            print(\"Lỗi: File không có đủ các cột cần thiết!\")\n",
        "            print(f\"Cần có: {required_cols}\")\n",
        "            print(f\"File có: {list(data.columns)}\")\n",
        "            return\n",
        "\n",
        "        # Tiền xử lý\n",
        "        data['Message'] = data['Message'].fillna('')\n",
        "        data['processed_subject'] = data['Subject'].apply(preprocess_text)\n",
        "        data['processed_message'] = data['Message'].apply(preprocess_text)\n",
        "        data['combined_text'] = data['processed_subject'] + ' ' + data['processed_message']\n",
        "\n",
        "        # Dự đoán\n",
        "        X_test = data['combined_text'].values\n",
        "        y_test = data['Spam/Ham'].values\n",
        "        predictions = nb_classifier.predict(X_test)\n",
        "\n",
        "        # Đánh giá\n",
        "        accuracy, metrics = evaluate_model(y_test, predictions)\n",
        "\n",
        "        print(f\"\\nKết quả đánh giá:\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        for c in metrics:\n",
        "            m = metrics[c]\n",
        "            print(f\"\\nLớp '{c}':\")\n",
        "            print(f\"  Precision: {m['precision']:.4f}\")\n",
        "            print(f\"  Recall: {m['recall']:.4f}\")\n",
        "            print(f\"  F1-score: {m['f1']:.4f}\")\n",
        "\n",
        "        # Chi tiết một số dự đoán\n",
        "        print(\"\\n5 dự đoán đầu tiên:\")\n",
        "        for i in range(min(5, len(data))):\n",
        "            print(f\"{i+1}. Thực tế: {y_test[i]}, Dự đoán: {predictions[i]}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Lỗi khi đọc file: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaRLBM_xaHN0",
        "outputId": "de0da0e3-24ce-4cec-8ba5-1d030a6bf33b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ĐÁNH GIÁ FILE: val.csv ===\n",
            "Đã đọc 3084 dòng từ file\n",
            "\n",
            "Kết quả đánh giá:\n",
            "Accuracy: 0.9887\n",
            "\n",
            "Lớp 'spam':\n",
            "  Precision: 0.9872\n",
            "  Recall: 0.9904\n",
            "  F1-score: 0.9888\n",
            "\n",
            "Lớp 'ham':\n",
            "  Precision: 0.9901\n",
            "  Recall: 0.9869\n",
            "  F1-score: 0.9885\n",
            "\n",
            "5 dự đoán đầu tiên:\n",
            "1. Thực tế: ham, Dự đoán: ham\n",
            "2. Thực tế: ham, Dự đoán: ham\n",
            "3. Thực tế: ham, Dự đoán: ham\n",
            "4. Thực tế: ham, Dự đoán: ham\n",
            "5. Thực tế: ham, Dự đoán: ham\n"
          ]
        }
      ],
      "source": [
        "# Test với file val.csv\n",
        "evaluate_csv_file('val.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d80Tq9haHN1"
      },
      "source": [
        "## 5. Phân tích và cải thiện\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmZk-cwiaHN1"
      },
      "source": [
        "### 5.1 Phân tích các từ quan trọng\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K55UhmxkaHN1"
      },
      "outputs": [],
      "source": [
        "def get_top_words_per_class(n=20):\n",
        "    \"\"\"\n",
        "    Lấy n từ có xác suất cao nhất cho mỗi lớp\n",
        "    \"\"\"\n",
        "    print(f\"=== TOP {n} TỪ QUAN TRỌNG CHO MỖI LỚP ===\")\n",
        "\n",
        "    for c in nb_classifier.classes:\n",
        "        # Lấy log odds ratio: log(P(word|class)) - log(P(word|not_class))\n",
        "        word_scores = {}\n",
        "\n",
        "        for word in nb_classifier.vocab:\n",
        "            if word in nb_classifier.word_probs[c]:\n",
        "                # Log probability của từ trong lớp hiện tại\n",
        "                log_prob_c = math.log(nb_classifier.word_probs[c][word])\n",
        "\n",
        "                # Log probability trung bình của từ trong các lớp khác\n",
        "                other_classes = [cls for cls in nb_classifier.classes if cls != c]\n",
        "                avg_log_prob_other = sum(math.log(nb_classifier.word_probs[cls].get(word,\n",
        "                                                  nb_classifier.word_probs[cls]['<UNK>']))\n",
        "                                        for cls in other_classes) / len(other_classes)\n",
        "\n",
        "                # Score = difference\n",
        "                word_scores[word] = log_prob_c - avg_log_prob_other\n",
        "\n",
        "        # Sắp xếp và lấy top n\n",
        "        top_words = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)[:n]\n",
        "\n",
        "        print(f\"\\nLớp '{c}':\")\n",
        "        for i, (word, score) in enumerate(top_words, 1):\n",
        "            print(f\"  {i:2d}. {word:20s} (score: {score:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G30TW3l5aHN2",
        "outputId": "54d58b50-95c7-401d-e192-ccfc36af12dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TOP 20 TỪ QUAN TRỌNG CHO MỖI LỚP ===\n",
            "\n",
            "Lớp 'spam':\n",
            "   1. pill                 (score: 7.5283)\n",
            "   2. viagra               (score: 7.3001)\n",
            "   3. invest_advic         (score: 7.1833)\n",
            "   4. xp                   (score: 7.1557)\n",
            "   5. ciali                (score: 6.9437)\n",
            "   6. within_email         (score: 6.8876)\n",
            "   7. computron            (score: 6.8175)\n",
            "   8. voip                 (score: 6.8139)\n",
            "   9. ook                  (score: 6.6423)\n",
            "  10. computron_com        (score: 6.6091)\n",
            "  11. photoshop            (score: 6.5518)\n",
            "  12. mx_2004              (score: 6.5456)\n",
            "  13. window_xp            (score: 6.5424)\n",
            "  14. ook_statement        (score: 6.5154)\n",
            "  15. next_kin             (score: 6.5025)\n",
            "  16. wysak                (score: 6.4777)\n",
            "  17. inciud               (score: 6.4557)\n",
            "  18. wiil                 (score: 6.4523)\n",
            "  19. adob_photoshop       (score: 6.4315)\n",
            "  20. technoiogi           (score: 6.4262)\n",
            "\n",
            "Lớp 'ham':\n",
            "   1. enron                (score: 10.4356)\n",
            "   2. hou_ect              (score: 9.3905)\n",
            "   3. ect_ect              (score: 9.3667)\n",
            "   4. enron_enron          (score: 8.4317)\n",
            "   5. kaminski             (score: 8.1961)\n",
            "   6. enron_com            (score: 8.1203)\n",
            "   7. ect_cc               (score: 7.9453)\n",
            "   8. j_kaminski           (score: 7.8232)\n",
            "   9. vinc_j               (score: 7.8191)\n",
            "  10. corp_enron           (score: 7.7652)\n",
            "  11. ena                  (score: 7.4650)\n",
            "  12. mmbtu                (score: 7.4059)\n",
            "  13. cc_subject           (score: 7.3275)\n",
            "  14. lon_ect              (score: 7.2805)\n",
            "  15. ect_subject          (score: 7.2671)\n",
            "  16. dbcap_97             (score: 7.2548)\n",
            "  17. dbcap                (score: 7.2548)\n",
            "  18. 97_data              (score: 7.2548)\n",
            "  19. kaminski_hou         (score: 7.1883)\n",
            "  20. hourahead            (score: 7.1869)\n"
          ]
        }
      ],
      "source": [
        "get_top_words_per_class(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKm0uLBWaHN2"
      },
      "source": [
        "### 5.2 Thử nghiệm với các tham số smoothing khác nhau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drm_1yP4aHN2",
        "outputId": "7c3d0223-f23c-4ece-ca9d-80c9358cb4af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== THỬ NGHIỆM VỚI CÁC GIÁ TRỊ ALPHA KHÁC NHAU ===\n",
            "\n",
            "==================================================\n",
            "Alpha = 0.1\n",
            "==================================================\n",
            "Tính prior probability...\n",
            "P(spam) = 0.5079\n",
            "P(ham) = 0.4921\n",
            "\n",
            "Đang đếm từ để xây dựng từ vựng...\n",
            "Tổng số từ duy nhất ban đầu: 117033\n",
            "Kích thước từ vựng sau khi lọc (xuất hiện >= 3 lần): 46248\n",
            "\n",
            "Tính likelihood với Laplace smoothing...\n",
            "\n",
            "Lớp spam: 1815525 từ (trong vocab)\n",
            "\n",
            "Lớp ham: 1996437 từ (trong vocab)\n",
            "\n",
            "Huấn luyện hoàn tất!\n",
            "Validation Accuracy: 0.9861\n",
            "\n",
            "\n",
            "==================================================\n",
            "Alpha = 0.5\n",
            "==================================================\n",
            "Tính prior probability...\n",
            "P(spam) = 0.5079\n",
            "P(ham) = 0.4921\n",
            "\n",
            "Đang đếm từ để xây dựng từ vựng...\n",
            "Tổng số từ duy nhất ban đầu: 117033\n",
            "Kích thước từ vựng sau khi lọc (xuất hiện >= 3 lần): 46248\n",
            "\n",
            "Tính likelihood với Laplace smoothing...\n",
            "\n",
            "Lớp spam: 1815525 từ (trong vocab)\n",
            "\n",
            "Lớp ham: 1996437 từ (trong vocab)\n",
            "\n",
            "Huấn luyện hoàn tất!\n",
            "Validation Accuracy: 0.9867\n",
            "\n",
            "\n",
            "==================================================\n",
            "Alpha = 1.0\n",
            "==================================================\n",
            "Tính prior probability...\n",
            "P(spam) = 0.5079\n",
            "P(ham) = 0.4921\n",
            "\n",
            "Đang đếm từ để xây dựng từ vựng...\n",
            "Tổng số từ duy nhất ban đầu: 117033\n",
            "Kích thước từ vựng sau khi lọc (xuất hiện >= 3 lần): 46248\n",
            "\n",
            "Tính likelihood với Laplace smoothing...\n",
            "\n",
            "Lớp spam: 1815525 từ (trong vocab)\n",
            "\n",
            "Lớp ham: 1996437 từ (trong vocab)\n",
            "\n",
            "Huấn luyện hoàn tất!\n",
            "Validation Accuracy: 0.9822\n",
            "\n",
            "\n",
            "==================================================\n",
            "Alpha = 2.0\n",
            "==================================================\n",
            "Tính prior probability...\n",
            "P(spam) = 0.5079\n",
            "P(ham) = 0.4921\n",
            "\n",
            "Đang đếm từ để xây dựng từ vựng...\n",
            "Tổng số từ duy nhất ban đầu: 117033\n",
            "Kích thước từ vựng sau khi lọc (xuất hiện >= 3 lần): 46248\n",
            "\n",
            "Tính likelihood với Laplace smoothing...\n",
            "\n",
            "Lớp spam: 1815525 từ (trong vocab)\n",
            "\n",
            "Lớp ham: 1996437 từ (trong vocab)\n",
            "\n",
            "Huấn luyện hoàn tất!\n",
            "Validation Accuracy: 0.9805\n",
            "\n",
            "\n",
            "==================================================\n",
            "Alpha = 5.0\n",
            "==================================================\n",
            "Tính prior probability...\n",
            "P(spam) = 0.5079\n",
            "P(ham) = 0.4921\n",
            "\n",
            "Đang đếm từ để xây dựng từ vựng...\n",
            "Tổng số từ duy nhất ban đầu: 117033\n",
            "Kích thước từ vựng sau khi lọc (xuất hiện >= 3 lần): 46248\n",
            "\n",
            "Tính likelihood với Laplace smoothing...\n",
            "\n",
            "Lớp spam: 1815525 từ (trong vocab)\n",
            "\n",
            "Lớp ham: 1996437 từ (trong vocab)\n",
            "\n",
            "Huấn luyện hoàn tất!\n",
            "Validation Accuracy: 0.9809\n",
            "\n",
            "\n",
            "\n",
            "Alpha tốt nhất: 0.5 với accuracy: 0.9867\n"
          ]
        }
      ],
      "source": [
        "print(\"=== THỬ NGHIỆM VỚI CÁC GIÁ TRỊ ALPHA KHÁC NHAU ===\\n\")\n",
        "\n",
        "alphas = [0.1, 0.5, 1.0, 2.0, 5.0]\n",
        "results = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"Alpha = {alpha}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Train model với alpha mới\n",
        "    nb_temp = NaiveBayesClassifier(alpha=alpha)\n",
        "    nb_temp.fit(X_train, y_train)\n",
        "\n",
        "    # Đánh giá\n",
        "    val_pred = nb_temp.predict(X_val)\n",
        "    accuracy, _ = evaluate_model(y_val, val_pred)\n",
        "\n",
        "    results.append({'alpha': alpha, 'accuracy': accuracy})\n",
        "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Tìm alpha tốt nhất\n",
        "best_result = max(results, key=lambda x: x['accuracy'])\n",
        "print(f\"\\nAlpha tốt nhất: {best_result['alpha']} với accuracy: {best_result['accuracy']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_1cxjS1hTUQ",
        "outputId": "74d8bccf-a6a5-4f4c-f12a-6dd0daee233a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tính prior probability...\n",
            "P(spam) = 0.5079\n",
            "P(ham) = 0.4921\n",
            "\n",
            "Đang đếm từ để xây dựng từ vựng...\n",
            "Tổng số từ duy nhất ban đầu: 1343331\n",
            "Kích thước từ vựng sau khi lọc (xuất hiện >= 3 lần): 300431\n",
            "\n",
            "Tính likelihood với Laplace smoothing...\n",
            "\n",
            "Lớp spam: 3098034 từ (trong vocab)\n",
            "\n",
            "Lớp ham: 3396182 từ (trong vocab)\n",
            "\n",
            "Huấn luyện hoàn tất!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.NaiveBayesClassifier at 0x78c3bb380d90>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "# áp dụng alpha tốt nhất\n",
        "nb_classifier.alpha = best_result['alpha']\n",
        "nb_classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQLu3aiBaHN2"
      },
      "source": [
        "## 6. Ví dụ test thực tế"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atZliJKCaHN2"
      },
      "outputs": [],
      "source": [
        "test_emails = [\n",
        "    {\n",
        "        'subject': 'Congratulations! You have won 1 million dollars',\n",
        "        'message': 'Click here now to claim your prize. Limited time offer!'\n",
        "    },\n",
        "    {\n",
        "        'subject': 'Project Team Meeting',\n",
        "        'message': 'Hi team, we will have a meeting tomorrow at 2 PM to discuss the project progress.'\n",
        "    },\n",
        "    {\n",
        "        'subject': '90% OFF - BUY NOW',\n",
        "        'message': 'Special promotion for today only! Buy now or you will miss out!!!'\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oK8kkYPaHN3",
        "outputId": "d870a18e-16ee-40af-d6d1-17b28e47dc31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TEST VỚI CÁC EMAIL MẪU ===\n",
            "\n",
            "Email 1:\n",
            "Tiêu đề: \"Congratulations! You have won 1 million dollars\"\n",
            "Nội dung: \"Click here now to claim your prize. Limited time offer!...\"\n",
            "Dự đoán: SPAM\n",
            "Xác suất:\n",
            "  - spam: 1.0000\n",
            "  - ham: 0.0000\n",
            "\n",
            "Email 2:\n",
            "Tiêu đề: \"Project Team Meeting\"\n",
            "Nội dung: \"Hi team, we will have a meeting tomorrow at 2 PM to discuss the project progress....\"\n",
            "Dự đoán: HAM\n",
            "Xác suất:\n",
            "  - spam: 0.0000\n",
            "  - ham: 1.0000\n",
            "\n",
            "Email 3:\n",
            "Tiêu đề: \"90% OFF - BUY NOW\"\n",
            "Nội dung: \"Special promotion for today only! Buy now or you will miss out!!!...\"\n",
            "Dự đoán: SPAM\n",
            "Xác suất:\n",
            "  - spam: 0.9980\n",
            "  - ham: 0.0020\n"
          ]
        }
      ],
      "source": [
        "print(\"=== TEST VỚI CÁC EMAIL MẪU ===\")\n",
        "for i, email in enumerate(test_emails, 1):\n",
        "    print(f\"\\nEmail {i}:\")\n",
        "    print(f\"Tiêu đề: \\\"{email['subject']}\\\"\")\n",
        "    print(f\"Nội dung: \\\"{email['message'][:100]}...\\\"\")\n",
        "\n",
        "    # Tiền xử lý và dự đoán\n",
        "    combined = preprocess_text(email['subject']) + ' ' + preprocess_text(email['message'])\n",
        "    prediction, log_pros = nb_classifier._predict_single(combined)\n",
        "\n",
        "    print(f\"Dự đoán: {prediction.upper()}\")\n",
        "\n",
        "    max_log_prob = max(log_pros.values())\n",
        "    exp_probs = {c: math.exp(log_prob - max_log_prob) for c, log_prob in log_pros.items()}\n",
        "    total = sum(exp_probs.values())\n",
        "    final_probs = {c: exp_prob / total for c, exp_prob in exp_probs.items()}\n",
        "\n",
        "    print(f\"Xác suất:\")\n",
        "    print(f\"  - spam: {final_probs.get('spam', 0):.4f}\")\n",
        "    print(f\"  - ham: {final_probs.get('ham', 0):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kLIegdIaHN3"
      },
      "source": [
        "## 7. Kết luận\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjvzKSDnaHN3",
        "outputId": "4d765abd-66e4-4fa7-e7e0-e9fe28e05435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TÓM TẮT KẾT QUẢ ===\n",
            "1. Kích thước dữ liệu:\n",
            "   - Train: 27284 emails\n",
            "   - Validation: 3084 emails\n",
            "   - Từ vựng: 300431 từ\n",
            "\n",
            "2. Hiệu suất mô hình:\n",
            "   - Train accuracy: 0.9947\n",
            "   - Validation accuracy: 0.9887\n",
            "\n",
            "3. Tham số mô hình:\n",
            "   - Smoothing (alpha): 0.5\n",
            "   - Phương pháp: Naive Bayes với Laplace smoothing\n",
            "\n",
            "4. Ưu điểm của mô hình:\n",
            "   - Đơn giản, dễ hiểu và cài đặt\n",
            "   - Huấn luyện nhanh\n",
            "   - Hoạt động tốt với dữ liệu văn bản\n",
            "   - Xử lý tốt với từ chưa xuất hiện nhờ smoothing\n",
            "\n",
            "5. Hạn chế và cải thiện:\n",
            "   - Giả định độc lập có điều kiện có thể không phù hợp\n",
            "   - Có thể cải thiện bằng cách:\n",
            "     + Sử dụng n-grams thay vì unigrams\n",
            "     + Feature engineering tốt hơn\n",
            "     + Kết hợp với các đặc trưng khác (độ dài email, số lượng ký tự đặc biệt, ...)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n=== TÓM TẮT KẾT QUẢ ===\")\n",
        "print(f\"1. Kích thước dữ liệu:\")\n",
        "print(f\"   - Train: {len(train_data)} emails\")\n",
        "print(f\"   - Validation: {len(val_data)} emails\")\n",
        "print(f\"   - Từ vựng: {len(nb_classifier.vocab)} từ\")\n",
        "\n",
        "print(f\"\\n2. Hiệu suất mô hình:\")\n",
        "print(f\"   - Train accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"   - Validation accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "print(f\"\\n3. Tham số mô hình:\")\n",
        "print(f\"   - Smoothing (alpha): {nb_classifier.alpha}\")\n",
        "print(f\"   - Phương pháp: Naive Bayes với Laplace smoothing\")\n",
        "\n",
        "print(\"\\n4. Ưu điểm của mô hình:\")\n",
        "print(\"   - Đơn giản, dễ hiểu và cài đặt\")\n",
        "print(\"   - Huấn luyện nhanh\")\n",
        "print(\"   - Hoạt động tốt với dữ liệu văn bản\")\n",
        "print(\"   - Xử lý tốt với từ chưa xuất hiện nhờ smoothing\")\n",
        "\n",
        "print(\"\\n5. Hạn chế và cải thiện:\")\n",
        "print(\"   - Giả định độc lập có điều kiện có thể không phù hợp\")\n",
        "print(\"   - Có thể cải thiện bằng cách:\")\n",
        "print(\"     + Sử dụng n-grams thay vì unigrams\")\n",
        "print(\"     + Feature engineering tốt hơn\")\n",
        "print(\"     + Kết hợp với các đặc trưng khác (độ dài email, số lượng ký tự đặc biệt, ...)\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}