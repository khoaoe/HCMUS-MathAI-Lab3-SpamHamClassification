{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2p4uuBsaHNn"
      },
      "source": [
        "# Lab 3 - Phân loại thư rác với Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7kBbpD7aHNp"
      },
      "source": [
        "## Thông tin nhóm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeMjqEXvaHNp"
      },
      "source": [
        "## 1. Import thư viện và tải dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c9hEDCsa20L",
        "outputId": "090833fe-f74b-4851-c941-12768610ada7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đã import các thư viện.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import Counter, defaultdict\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Đã import các thư viện.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKIyOWokl6pu",
        "outputId": "d88c8720-2d02-4ab6-ece4-c3e8baad9341"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đã tải và sẵn sàng sử dụng stopwords.\n"
          ]
        }
      ],
      "source": [
        "# Lấy danh sách stop words\n",
        "import nltk\n",
        "\n",
        "try:\n",
        "    # Thử tìm tài nguyên stopwords\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    # Nếu không tìm thấy (gây ra LookupError), thì mới tải về\n",
        "    print(\"Tài nguyên stopwords chưa được tải, đang tiến hành tải...\")\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "print(\"Đã tải và sẵn sàng sử dụng stopwords.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "LdEQ47baaHNq",
        "outputId": "a07669f9-395c-4208-a498-82d6996417a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đang tải dữ liệu...\n",
            "Kích thước tập train: (17252, 6)\n",
            "Kích thước tập validation: (3084, 6)\n",
            "\n",
            "5 dòng đầu tiên của tập train:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 17252,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6141,\n        \"min\": 0,\n        \"max\": 21216,\n        \"num_unique_values\": 17252,\n        \"samples\": [\n          13429,\n          10822,\n          4894\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Message ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6141,\n        \"min\": 0,\n        \"max\": 21216,\n        \"num_unique_values\": 17252,\n        \"samples\": [\n          13429,\n          10822,\n          4894\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subject\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13834,\n        \"samples\": [\n          \"pre - approved application sat , 06 nov 2004 02 : 08 : 48 - 0800\",\n          \"re : hl & p 6 / 00\",\n          \"day 1 list additions part 2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16189,\n        \"samples\": [\n          \"f . y . i .\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by kevin g moore / hou / ect on 01 / 07 / 2000 06 : 03\\nam - - - - - - - - - - - - - - - - - - - - - - - - - - -\\nkevin g moore\\n01 / 07 / 2000 06 : 03 am\\nto : tommy garza / hou / ect @ ect\\ncc :\\nsubject : re : flat screens\\nthanks tommy ,\\nthe locations are correct .\\neb 3131 b and eb 3132 b .\\nthe persons at the locations\\nare trisha tlapek and michael sergeev .\\nthanks\\nalso we need a computer for roman zadorozhny\\nlocation ebl 972 b .\\nplease inform me on this . . . . . . . . .\\nkevin moore\",\n          \"( see attached file : hplno 302 . xls )\\n- hplno 302 . xls\",\n          \"hi paliourg ,\\nit ' s katie remember me ? we met online last week . anyways i just signed up to the largest adult dating site ever !\\nme and my friends , estelle , adela , and brandi\\nare waiting for you ; ) so\\nnever cackle unless you lay .\\nthe bigger they are the harder they fall . . silence is less injurious than a bad reply . . nothing is ill said if it is not ill taken . . a fool in a gown is none the wiser . .\\noaks may fall when reeds take the storm .\\ntoo many clicks spoil the browse .\\nno more ?\\n. better safe than sorry . . true beauty lies within . . a bad excuse is better then none . .\\nalways you are to be rich next year . . anger and hate hinder good counsel . . an elephant never forgets . .\\nfore - warned is fore - armed . . don ' t cross the bridge till you come to it . . variety is the spice of life . .\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spam/Ham\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0051711818748252,\n        \"min\": -3.6375730003480458,\n        \"max\": 3.6127381957087294,\n        \"num_unique_values\": 17252,\n        \"samples\": [\n          1.1891115014112177,\n          1.933673988398083\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "train_data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-6e848958-836a-4886-aeff-64a7bcc58ea3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Message ID</th>\n",
              "      <th>Subject</th>\n",
              "      <th>Message</th>\n",
              "      <th>Spam/Ham</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>christmas tree farm pictures</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ham</td>\n",
              "      <td>0.038415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>vastar resources , inc .</td>\n",
              "      <td>gary , production from the high island larger ...</td>\n",
              "      <td>ham</td>\n",
              "      <td>0.696509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>calpine daily gas nomination</td>\n",
              "      <td>- calpine daily gas nomination 1 . doc</td>\n",
              "      <td>ham</td>\n",
              "      <td>0.587792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>re : issue</td>\n",
              "      <td>fyi - see note below - already done .\\nstella\\...</td>\n",
              "      <td>ham</td>\n",
              "      <td>-0.055438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>mcmullen gas for 11 / 99</td>\n",
              "      <td>jackie ,\\nsince the inlet to 3 river plant is ...</td>\n",
              "      <td>ham</td>\n",
              "      <td>-0.419658</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e848958-836a-4886-aeff-64a7bcc58ea3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6e848958-836a-4886-aeff-64a7bcc58ea3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6e848958-836a-4886-aeff-64a7bcc58ea3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ff8ccc4a-04ea-4692-989d-79b45a80bdbd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff8ccc4a-04ea-4692-989d-79b45a80bdbd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ff8ccc4a-04ea-4692-989d-79b45a80bdbd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Unnamed: 0  Message ID                       Subject  \\\n",
              "0           0           0  christmas tree farm pictures   \n",
              "1           1           1      vastar resources , inc .   \n",
              "2           2           2  calpine daily gas nomination   \n",
              "3           3           3                    re : issue   \n",
              "4           5           5      mcmullen gas for 11 / 99   \n",
              "\n",
              "                                             Message Spam/Ham     split  \n",
              "0                                                NaN      ham  0.038415  \n",
              "1  gary , production from the high island larger ...      ham  0.696509  \n",
              "2             - calpine daily gas nomination 1 . doc      ham  0.587792  \n",
              "3  fyi - see note below - already done .\\nstella\\...      ham -0.055438  \n",
              "4  jackie ,\\nsince the inlet to 3 river plant is ...      ham -0.419658  "
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Đọc dữ liệu\n",
        "print(\"Đang tải dữ liệu...\")\n",
        "train_data = pd.read_csv('train.csv',  on_bad_lines='skip', engine='python')\n",
        "val_data = pd.read_csv('val.csv',  on_bad_lines='skip', engine='python')\n",
        "\n",
        "print(f\"Kích thước tập train: {train_data.shape}\")\n",
        "print(f\"Kích thước tập validation: {val_data.shape}\")\n",
        "print(\"\\n5 dòng đầu tiên của tập train:\")\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x-UGbDeaHNs"
      },
      "source": [
        "## 2. Tiền xử lý dữ liệu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM-cQTdjaHNs"
      },
      "source": [
        "### 2.1 Kiểm tra và làm sạch dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anzj8tzkaHNt",
        "outputId": "ad2de955-0436-4e33-889d-25a9c53a7640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kiểm tra dữ liệu null:\n",
            "Unnamed: 0      0\n",
            "Message ID      0\n",
            "Subject       178\n",
            "Message       325\n",
            "Spam/Ham        0\n",
            "split           0\n",
            "dtype: int64\n",
            "\n",
            "Kiểm tra dữ liệu null trong val set:\n",
            "Unnamed: 0     0\n",
            "Message ID     0\n",
            "Subject       29\n",
            "Message       35\n",
            "Spam/Ham       0\n",
            "split          0\n",
            "dtype: int64\n",
            "\n",
            "Số dòng trùng lặp trong train: 0\n",
            "Số dòng trùng lặp trong val: 0\n",
            "\n",
            "Phân phối nhãn trong tập train:\n",
            "Spam/Ham\n",
            "ham     11028\n",
            "spam     6224\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Phân phối nhãn trong tập val:\n",
            "Spam/Ham\n",
            "spam    1563\n",
            "ham     1521\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Kiểm tra dữ liệu null\n",
        "print(\"Kiểm tra dữ liệu null:\")\n",
        "print(train_data.isnull().sum())\n",
        "print(\"\\nKiểm tra dữ liệu null trong val set:\")\n",
        "print(val_data.isnull().sum())\n",
        "\n",
        "# Điền giá trị rỗng cho Message nếu có\n",
        "train_data['Message'] = train_data['Message'].fillna('')\n",
        "val_data['Message'] = val_data['Message'].fillna('')\n",
        "\n",
        "# Kiểm tra dữ liệu trùng lặp\n",
        "print(f\"\\nSố dòng trùng lặp trong train: {train_data.duplicated().sum()}\")\n",
        "print(f\"Số dòng trùng lặp trong val: {val_data.duplicated().sum()}\")\n",
        "\n",
        "# Loại bỏ dòng trùng lặp nếu có\n",
        "train_data = train_data.drop_duplicates().reset_index(drop=True)\n",
        "val_data = val_data.drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "# Kiểm tra phân phối nhãn\n",
        "print(\"\\nPhân phối nhãn trong tập train:\")\n",
        "print(train_data['Spam/Ham'].value_counts())\n",
        "print(\"\\nPhân phối nhãn trong tập val:\")\n",
        "print(val_data['Spam/Ham'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JF7xkUvaHNu"
      },
      "source": [
        "### 2.2 Tiền xử lý văn bản"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3Ddz_xSaHNv",
        "outputId": "b3f77d17-c3e5-4521-93fc-ad8d8e804d93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đang tiền xử lý văn bản...\n",
            "Ví dụ văn bản sau khi tiền xử lý:\n",
            "                        Subject             processed_subject\n",
            "0  christmas tree farm pictures  christmas tree farm pictures\n",
            "1      vastar resources , inc .          vastar resources inc\n",
            "2  calpine daily gas nomination  calpine daily gas nomination\n"
          ]
        }
      ],
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Tiền xử lý văn bản:\n",
        "    - Chuyển về chữ thường\n",
        "    - Loại bỏ ký tự đặc biệt, giữ lại chữ và số\n",
        "    - Loại bỏ khoảng trắng thừa\n",
        "    \"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "\n",
        "    # Chuyển về chữ thường\n",
        "    text = text.lower()\n",
        "\n",
        "    # Loại bỏ các ký tự đặc biệt, giữ lại chữ, số và khoảng trắng\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
        "\n",
        "    # Loại bỏ khoảng trắng thừa\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text\n",
        "\n",
        "# Áp dụng tiền xử lý cho dữ liệu\n",
        "print(\"Đang tiền xử lý văn bản...\")\n",
        "train_data['processed_subject'] = train_data['Subject'].apply(preprocess_text)\n",
        "train_data['processed_message'] = train_data['Message'].apply(preprocess_text)\n",
        "train_data['combined_text'] = train_data['processed_subject'] + ' ' + train_data['processed_message']\n",
        "\n",
        "val_data['processed_subject'] = val_data['Subject'].apply(preprocess_text)\n",
        "val_data['processed_message'] = val_data['Message'].apply(preprocess_text)\n",
        "val_data['combined_text'] = val_data['processed_subject'] + ' ' + val_data['processed_message']\n",
        "\n",
        "print(\"Ví dụ văn bản sau khi tiền xử lý:\")\n",
        "print(train_data[['Subject', 'processed_subject']].head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0epgOuNeaHNv"
      },
      "source": [
        "## 3. Xây dựng mô hình Naive Bayes từ đầu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anyhuTf0aHNw"
      },
      "source": [
        "### 3.1 Lý thuyết Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWRqGjPDaHNw"
      },
      "source": [
        "Naive Bayes Classifier cho phân loại văn bản:\n",
        "\n",
        "1. Theo Bayes' theorem:\n",
        "   P(class|document) = P(document|class) * P(class) / P(document)\n",
        "\n",
        "2. Với giả định Naive Bayes (độc lập có điều kiện):\n",
        "   P(document|class) = P(word1|class) * P(word2|class) * ... * P(wordn|class)\n",
        "\n",
        "3. Sử dụng log probability để tránh underflow:\n",
        "   log P(class|document) = log P(class) + Σ log P(word|class)\n",
        "\n",
        "4. Laplace smoothing để xử lý từ chưa xuất hiện:\n",
        "   P(word|class) = (count(word, class) + α) / (count(all words in class) + α * |V|)\n",
        "   với α = 1 (Laplace smoothing), |V| là kích thước từ vựng"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f41Ir4vRaHNw"
      },
      "source": [
        "### 3.2 Cài đặt Naive Bayes Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "sVa9Aef1aHNx"
      },
      "outputs": [],
      "source": [
        "class NaiveBayesClassifier:\n",
        "    def __init__(self, alpha=1.0):\n",
        "        \"\"\"\n",
        "        Khởi tạo Naive Bayes Classifier\n",
        "\n",
        "        Parameters:\n",
        "        - alpha: Tham số smoothing (mặc định = 1.0 cho Laplace smoothing)\n",
        "        \"\"\"\n",
        "        self.alpha = alpha\n",
        "        self.class_priors = {}\n",
        "        self.word_probs = {}\n",
        "        self.classes = []\n",
        "        self.vocab = set()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    def _tokenize(self, text):\n",
        "        \"\"\" Tách văn bản thành các từ VÀ LOẠI BỎ STOP WORDS \"\"\"\n",
        "        words = text.split()\n",
        "\n",
        "        # Trả về danh sách các từ không nằm trong danh sách stop_words\n",
        "        return [word for word in words if word not in self.stop_words]\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        Huấn luyện mô hình Naive Bayes\n",
        "\n",
        "        Parameters:\n",
        "        - X_train: Danh sách văn bản đã tiền xử lý\n",
        "        - y_train: Nhãn tương ứng\n",
        "        \"\"\"\n",
        "        # Lấy danh sách các lớp\n",
        "        self.classes = list(set(y_train))\n",
        "        n_docs = len(y_train)\n",
        "\n",
        "        # Tính prior probability cho mỗi lớp\n",
        "        print(\"Tính prior probability...\")\n",
        "        for c in self.classes:\n",
        "            self.class_priors[c] = sum(1 for y in y_train if y == c) / n_docs\n",
        "            print(f\"P({c}) = {self.class_priors[c]:.4f}\")\n",
        "\n",
        "        # Đếm từ cho mỗi lớp\n",
        "        word_counts = {c: Counter() for c in self.classes}\n",
        "        doc_counts = {c: 0 for c in self.classes}\n",
        "\n",
        "        print(\"\\nĐang đếm từ...\")\n",
        "        for text, label in zip(X_train, y_train):\n",
        "            words = self._tokenize(text)\n",
        "            doc_counts[label] += 1\n",
        "            for word in words:\n",
        "                word_counts[label][word] += 1\n",
        "                self.vocab.add(word)\n",
        "\n",
        "        vocab_size = len(self.vocab)\n",
        "        print(f\"Kích thước từ vựng: {vocab_size}\")\n",
        "\n",
        "        # Tính likelihood với Laplace smoothing\n",
        "        print(\"\\nTính likelihood với Laplace smoothing...\")\n",
        "        self.word_probs = {c: {} for c in self.classes}\n",
        "\n",
        "        for c in self.classes:\n",
        "            total_words = sum(word_counts[c].values())\n",
        "            print(f\"\\nLớp {c}: {total_words} từ\")\n",
        "\n",
        "            # Tính P(word|class) cho mỗi từ trong vocabulary\n",
        "            for word in self.vocab:\n",
        "                count = word_counts[c].get(word, 0)\n",
        "                # Laplace smoothing\n",
        "                self.word_probs[c][word] = (count + self.alpha) / (total_words + self.alpha * vocab_size)\n",
        "\n",
        "            # Tính xác suất cho từ chưa từng xuất hiện (unknown words)\n",
        "            self.word_probs[c]['<UNK>'] = self.alpha / (total_words + self.alpha * vocab_size)\n",
        "\n",
        "        print(\"\\nHuấn luyện hoàn tất!\")\n",
        "        return self\n",
        "\n",
        "    def _predict_single(self, text):\n",
        "        \"\"\"\n",
        "        Dự đoán nhãn cho một văn bản\n",
        "\n",
        "        Returns: (predicted_class, log_probabilities)\n",
        "        \"\"\"\n",
        "        words = self._tokenize(text)\n",
        "\n",
        "        # Tính log probability cho mỗi lớp\n",
        "        log_probs = {}\n",
        "\n",
        "        for c in self.classes:\n",
        "            # Bắt đầu với log prior\n",
        "            log_prob = math.log(self.class_priors[c])\n",
        "\n",
        "            # Cộng log likelihood của mỗi từ\n",
        "            for word in words:\n",
        "                if word in self.word_probs[c]:\n",
        "                    log_prob += math.log(self.word_probs[c][word])\n",
        "                else:\n",
        "                    # Từ chưa xuất hiện, sử dụng xác suất UNK\n",
        "                    log_prob += math.log(self.word_probs[c]['<UNK>'])\n",
        "\n",
        "            log_probs[c] = log_prob\n",
        "\n",
        "        # Chọn lớp có log probability cao nhất\n",
        "        predicted_class = max(log_probs, key=log_probs.get)\n",
        "\n",
        "        return predicted_class, log_probs\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        \"\"\"Dự đoán nhãn cho tập văn bản\"\"\"\n",
        "        predictions = []\n",
        "        for text in X_test:\n",
        "            pred, prob = self._predict_single(text)\n",
        "            predictions.append(pred)\n",
        "        return predictions\n",
        "\n",
        "    def predict_proba(self, X_test):\n",
        "        \"\"\"\n",
        "        Dự đoán xác suất cho mỗi lớp\n",
        "\n",
        "        Returns: List of dictionaries với xác suất cho mỗi lớp\n",
        "        \"\"\"\n",
        "        proba_list = []\n",
        "\n",
        "        for text in X_test:\n",
        "            _, log_probs = self._predict_single(text)\n",
        "\n",
        "            # Chuyển log probabilities về probabilities\n",
        "            # Sử dụng log-sum-exp trick để tránh overflow\n",
        "            max_log_prob = max(log_probs.values())\n",
        "            exp_probs = {c: math.exp(log_prob - max_log_prob)\n",
        "                        for c, log_prob in log_probs.items()}\n",
        "\n",
        "            # Normalize\n",
        "            total = sum(exp_probs.values())\n",
        "            probs = {c: exp_prob / total for c, exp_prob in exp_probs.items()}\n",
        "\n",
        "            proba_list.append(probs)\n",
        "\n",
        "        return proba_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7BEpwyGaHNx"
      },
      "source": [
        "### 3.3 Huấn luyện mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "hjBQVCacaHNy"
      },
      "outputs": [],
      "source": [
        "# Khởi tạo và huấn luyện mô hình\n",
        "nb_classifier = NaiveBayesClassifier(alpha=1.0)\n",
        "\n",
        "# Chuẩn bị dữ liệu\n",
        "X_train = train_data['combined_text'].values\n",
        "y_train = train_data['Spam/Ham'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6cU8P41fGq7",
        "outputId": "28f42433-25c9-4d4f-d3a3-c04710a482e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bắt đầu huấn luyện mô hình...\n",
            "Tính prior probability...\n",
            "P(spam) = 0.3608\n",
            "P(ham) = 0.6392\n",
            "\n",
            "Đang đếm từ...\n",
            "Kích thước từ vựng: 105797\n",
            "\n",
            "Tính likelihood với Laplace smoothing...\n",
            "\n",
            "Lớp spam: 821355 từ\n",
            "\n",
            "Lớp ham: 1638569 từ\n",
            "\n",
            "Huấn luyện hoàn tất!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<__main__.NaiveBayesClassifier at 0x7d7783f2b990>"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Bắt đầu huấn luyện mô hình...\")\n",
        "nb_classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95dWxvj8aHNy"
      },
      "source": [
        "### 3.4 Đánh giá mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "hwddYPCaaHNy"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Đánh giá mô hình với các metrics:\n",
        "    - Accuracy\n",
        "    - Precision, Recall, F1-score cho mỗi lớp\n",
        "    - Confusion Matrix\n",
        "    \"\"\"\n",
        "\n",
        "    # Accuracy\n",
        "    accuracy = sum(y_t == y_p for y_t, y_p in zip(y_true, y_pred)) / len(y_true)\n",
        "\n",
        "    # Confusion Matrix và metrics cho mỗi lớp\n",
        "    classes = list(set(y_true))\n",
        "    metrics = {}\n",
        "\n",
        "    for c in classes:\n",
        "        # True Positive, False Positive, False Negative, True Negative\n",
        "        tp = sum((y_t == c) and (y_p == c) for y_t, y_p in zip(y_true, y_pred))\n",
        "        fp = sum((y_t != c) and (y_p == c) for y_t, y_p in zip(y_true, y_pred))\n",
        "        fn = sum((y_t == c) and (y_p != c) for y_t, y_p in zip(y_true, y_pred))\n",
        "        tn = sum((y_t != c) and (y_p != c) for y_t, y_p in zip(y_true, y_pred))\n",
        "\n",
        "        # Precision, Recall, F1\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        metrics[c] = {\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1,\n",
        "            'tp': tp, 'fp': fp, 'fn': fn, 'tn': tn\n",
        "        }\n",
        "\n",
        "    return accuracy, metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdcZFi_1fCSp",
        "outputId": "ce0f9b43-d48f-4750-d8c9-2b88831c696a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đánh giá trên tập train:\n",
            "Accuracy: 0.9870\n",
            "\n",
            "Lớp 'spam':\n",
            "  Precision: 0.9907\n",
            "  Recall: 0.9732\n",
            "  F1-score: 0.9818\n",
            "\n",
            "Lớp 'ham':\n",
            "  Precision: 0.9850\n",
            "  Recall: 0.9948\n",
            "  F1-score: 0.9899\n",
            "\n",
            "Confusion Matrix:\n",
            "             Predicted ↓\n",
            "Actual ↓    spam    ham\n",
            "spam        6057     167\n",
            "ham           57   10971\n",
            "\n",
            "==================================================\n",
            "Đánh giá trên tập validation:\n",
            "Accuracy: 0.9812\n",
            "\n",
            "Lớp 'spam':\n",
            "  Precision: 0.9896\n",
            "  Recall: 0.9731\n",
            "  F1-score: 0.9813\n",
            "\n",
            "Lớp 'ham':\n",
            "  Precision: 0.9729\n",
            "  Recall: 0.9895\n",
            "  F1-score: 0.9811\n",
            "\n",
            "Confusion Matrix:\n",
            "             Predicted ↓\n",
            "Actual ↓    spam    ham\n",
            "spam        1521      42\n",
            "ham           16    1505\n"
          ]
        }
      ],
      "source": [
        "# Đánh giá trên tập train\n",
        "print(\"Đánh giá trên tập train:\")\n",
        "train_predictions = nb_classifier.predict(X_train)\n",
        "train_accuracy, train_metrics = evaluate_model(y_train, train_predictions)\n",
        "\n",
        "print(f\"Accuracy: {train_accuracy:.4f}\")\n",
        "for c in train_metrics:\n",
        "    m = train_metrics[c]\n",
        "    print(f\"\\nLớp '{c}':\")\n",
        "    print(f\"  Precision: {m['precision']:.4f}\")\n",
        "    print(f\"  Recall: {m['recall']:.4f}\")\n",
        "    print(f\"  F1-score: {m['f1']:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(\"             Predicted ↓\")\n",
        "print(\"Actual ↓    spam    ham\")\n",
        "for true_class in ['spam', 'ham']:\n",
        "    print(f\"{true_class:8s}\", end=\"\")\n",
        "    for pred_class in ['spam', 'ham']:\n",
        "        count = sum((y_t == true_class) and (y_p == pred_class)\n",
        "                   for y_t, y_p in zip(y_train, train_predictions))\n",
        "        print(f\"{count:8d}\", end=\"\")\n",
        "    print()\n",
        "\n",
        "# Đánh giá trên tập validation\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Đánh giá trên tập validation:\")\n",
        "X_val = val_data['combined_text'].values\n",
        "y_val = val_data['Spam/Ham'].values\n",
        "\n",
        "val_predictions = nb_classifier.predict(X_val)\n",
        "val_accuracy, val_metrics = evaluate_model(y_val, val_predictions)\n",
        "\n",
        "print(f\"Accuracy: {val_accuracy:.4f}\")\n",
        "for c in val_metrics:\n",
        "    m = val_metrics[c]\n",
        "    print(f\"\\nLớp '{c}':\")\n",
        "    print(f\"  Precision: {m['precision']:.4f}\")\n",
        "    print(f\"  Recall: {m['recall']:.4f}\")\n",
        "    print(f\"  F1-score: {m['f1']:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(\"             Predicted ↓\")\n",
        "print(\"Actual ↓    spam    ham\")\n",
        "for true_class in ['spam', 'ham']:\n",
        "    print(f\"{true_class:8s}\", end=\"\")\n",
        "    for pred_class in ['spam', 'ham']:\n",
        "        count = sum((y_t == true_class) and (y_p == pred_class)\n",
        "                   for y_t, y_p in zip(y_val, val_predictions))\n",
        "        print(f\"{count:8d}\", end=\"\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KC-DdpUaHNz"
      },
      "source": [
        "## 4. Thử nghiệm thực tế"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz8ILhBaaHNz"
      },
      "source": [
        "### 4.1 Chức năng 1: Dự đoán email người dùng nhập"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "1xo17wHEaHNz"
      },
      "outputs": [],
      "source": [
        "def predict_user_email():\n",
        "    \"\"\"\n",
        "    Cho phép người dùng nhập email và dự đoán spam/ham\n",
        "    \"\"\"\n",
        "    print(\"=== DỰ ĐOÁN EMAIL ===\")\n",
        "    subject = input(\"Nhập tiêu đề email: \")\n",
        "    message = input(\"Nhập nội dung email: \")\n",
        "\n",
        "    # Tiền xử lý\n",
        "    processed_subject = preprocess_text(subject)\n",
        "    processed_message = preprocess_text(message)\n",
        "    combined = processed_subject + ' ' + processed_message\n",
        "\n",
        "    # Dự đoán\n",
        "    prediction, log_probs = nb_classifier._predict_single(combined)\n",
        "\n",
        "    # Tính xác suất\n",
        "    max_log_prob = max(log_probs.values())\n",
        "    exp_probs = {c: math.exp(log_prob - max_log_prob)\n",
        "                for c, log_prob in log_probs.items()}\n",
        "    total = sum(exp_probs.values())\n",
        "    probs = {c: exp_prob / total for c, exp_prob in exp_probs.items()}\n",
        "\n",
        "    print(f\"\\nKết quả dự đoán: {prediction.upper()}\")\n",
        "    print(f\"Xác suất spam: {probs['spam']:.4f}\")\n",
        "    print(f\"Xác suất ham: {probs['ham']:.4f}\")\n",
        "\n",
        "    return prediction, probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Uc5-mllaHN0",
        "outputId": "0755ccdb-2d2b-4e15-a91e-fb7b8cb8122b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== DỰ ĐOÁN EMAIL ===\n",
            "Nhập tiêu đề email: abcdefg\n",
            "Nhập nội dung email: ádasdasdasdasd\n",
            "\n",
            "Kết quả dự đoán: SPAM\n",
            "Xác suất spam: 0.6664\n",
            "Xác suất ham: 0.3336\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('spam', {'spam': 0.6664190560483, 'ham': 0.33358094395170007})"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test chức năng\n",
        "predict_user_email()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73b3ld3VaHN0"
      },
      "source": [
        "### 4.2 Chức năng 2: Đánh giá file CSV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "iuExLxrfaHN0"
      },
      "outputs": [],
      "source": [
        "def evaluate_csv_file(filename):\n",
        "    \"\"\"\n",
        "    Đọc và đánh giá mô hình trên file CSV\n",
        "    File CSV cần có cấu trúc giống val.csv\n",
        "    \"\"\"\n",
        "    print(f\"=== ĐÁNH GIÁ FILE: {filename} ===\")\n",
        "\n",
        "    try:\n",
        "        # Đọc file\n",
        "        data = pd.read_csv(filename)\n",
        "        print(f\"Đã đọc {len(data)} dòng từ file\")\n",
        "\n",
        "        # Kiểm tra cấu trúc\n",
        "        required_cols = ['Subject', 'Message', 'Spam/Ham']\n",
        "        if not all(col in data.columns for col in required_cols):\n",
        "            print(\"Lỗi: File không có đủ các cột cần thiết!\")\n",
        "            print(f\"Cần có: {required_cols}\")\n",
        "            print(f\"File có: {list(data.columns)}\")\n",
        "            return\n",
        "\n",
        "        # Tiền xử lý\n",
        "        data['Message'] = data['Message'].fillna('')\n",
        "        data['processed_subject'] = data['Subject'].apply(preprocess_text)\n",
        "        data['processed_message'] = data['Message'].apply(preprocess_text)\n",
        "        data['combined_text'] = data['processed_subject'] + ' ' + data['processed_message']\n",
        "\n",
        "        # Dự đoán\n",
        "        X_test = data['combined_text'].values\n",
        "        y_test = data['Spam/Ham'].values\n",
        "        predictions = nb_classifier.predict(X_test)\n",
        "\n",
        "        # Đánh giá\n",
        "        accuracy, metrics = evaluate_model(y_test, predictions)\n",
        "\n",
        "        print(f\"\\nKết quả đánh giá:\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        for c in metrics:\n",
        "            m = metrics[c]\n",
        "            print(f\"\\nLớp '{c}':\")\n",
        "            print(f\"  Precision: {m['precision']:.4f}\")\n",
        "            print(f\"  Recall: {m['recall']:.4f}\")\n",
        "            print(f\"  F1-score: {m['f1']:.4f}\")\n",
        "\n",
        "        # Chi tiết một số dự đoán\n",
        "        print(\"\\n5 dự đoán đầu tiên:\")\n",
        "        for i in range(min(5, len(data))):\n",
        "            print(f\"{i+1}. Thực tế: {y_test[i]}, Dự đoán: {predictions[i]}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Lỗi khi đọc file: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaRLBM_xaHN0",
        "outputId": "a852e45e-9bd3-469f-d357-854c31070ca7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ĐÁNH GIÁ FILE: val.csv ===\n",
            "Đã đọc 3084 dòng từ file\n",
            "\n",
            "Kết quả đánh giá:\n",
            "Accuracy: 0.9812\n",
            "\n",
            "Lớp 'spam':\n",
            "  Precision: 0.9896\n",
            "  Recall: 0.9731\n",
            "  F1-score: 0.9813\n",
            "\n",
            "Lớp 'ham':\n",
            "  Precision: 0.9729\n",
            "  Recall: 0.9895\n",
            "  F1-score: 0.9811\n",
            "\n",
            "5 dự đoán đầu tiên:\n",
            "1. Thực tế: ham, Dự đoán: ham\n",
            "2. Thực tế: ham, Dự đoán: ham\n",
            "3. Thực tế: ham, Dự đoán: ham\n",
            "4. Thực tế: ham, Dự đoán: ham\n",
            "5. Thực tế: ham, Dự đoán: ham\n"
          ]
        }
      ],
      "source": [
        "# Test với file val.csv\n",
        "evaluate_csv_file('val.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d80Tq9haHN1"
      },
      "source": [
        "## 5. Phân tích và cải thiện\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmZk-cwiaHN1"
      },
      "source": [
        "### 5.1 Phân tích các từ quan trọng\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "K55UhmxkaHN1"
      },
      "outputs": [],
      "source": [
        "def get_top_words_per_class(n=20):\n",
        "    \"\"\"\n",
        "    Lấy n từ có xác suất cao nhất cho mỗi lớp\n",
        "    \"\"\"\n",
        "    print(f\"=== TOP {n} TỪ QUAN TRỌNG CHO MỖI LỚP ===\")\n",
        "\n",
        "    for c in nb_classifier.classes:\n",
        "        # Lấy log odds ratio: log(P(word|class)) - log(P(word|not_class))\n",
        "        word_scores = {}\n",
        "\n",
        "        for word in nb_classifier.vocab:\n",
        "            if word in nb_classifier.word_probs[c]:\n",
        "                # Log probability của từ trong lớp hiện tại\n",
        "                log_prob_c = math.log(nb_classifier.word_probs[c][word])\n",
        "\n",
        "                # Log probability trung bình của từ trong các lớp khác\n",
        "                other_classes = [cls for cls in nb_classifier.classes if cls != c]\n",
        "                avg_log_prob_other = sum(math.log(nb_classifier.word_probs[cls].get(word,\n",
        "                                                  nb_classifier.word_probs[cls]['<UNK>']))\n",
        "                                        for cls in other_classes) / len(other_classes)\n",
        "\n",
        "                # Score = difference\n",
        "                word_scores[word] = log_prob_c - avg_log_prob_other\n",
        "\n",
        "        # Sắp xếp và lấy top n\n",
        "        top_words = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)[:n]\n",
        "\n",
        "        print(f\"\\nLớp '{c}':\")\n",
        "        for i, (word, score) in enumerate(top_words, 1):\n",
        "            print(f\"  {i:2d}. {word:20s} (score: {score:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G30TW3l5aHN2",
        "outputId": "1fc39353-c598-48a4-d3e1-0f32fbc56727"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== TOP 20 TỪ QUAN TRỌNG CHO MỖI LỚP ===\n",
            "\n",
            "Lớp 'spam':\n",
            "   1. pills                (score: 7.6549)\n",
            "   2. viagra               (score: 7.2264)\n",
            "   3. xp                   (score: 7.1571)\n",
            "   4. computron            (score: 7.0504)\n",
            "   5. cialis               (score: 6.8486)\n",
            "   6. width                (score: 6.7323)\n",
            "   7. nbsp                 (score: 6.7211)\n",
            "   8. href                 (score: 6.6134)\n",
            "   9. voip                 (score: 6.4491)\n",
            "  10. paliourg             (score: 6.4159)\n",
            "  11. photoshop            (score: 6.3686)\n",
            "  12. xanax                (score: 6.1085)\n",
            "  13. bgcolor              (score: 6.0437)\n",
            "  14. ooking               (score: 6.0347)\n",
            "  15. valium               (score: 5.9839)\n",
            "  16. src                  (score: 5.9599)\n",
            "  17. meds                 (score: 5.9550)\n",
            "  18. pharmacy             (score: 5.9403)\n",
            "  19. rolex                (score: 5.9203)\n",
            "  20. php                  (score: 5.9050)\n",
            "\n",
            "Lớp 'ham':\n",
            "   1. enron                (score: 9.6232)\n",
            "   2. kaminski             (score: 7.6398)\n",
            "   3. ect                  (score: 7.4194)\n",
            "   4. ees                  (score: 6.7716)\n",
            "   5. dbcaps               (score: 6.7069)\n",
            "   6. hourahead            (score: 6.6390)\n",
            "   7. ena                  (score: 6.6264)\n",
            "   8. mmbtu                (score: 6.4250)\n",
            "   9. hpl                  (score: 6.2970)\n",
            "  10. crenshaw             (score: 6.2223)\n",
            "  11. 853                  (score: 6.2170)\n",
            "  12. enronxgate           (score: 6.2160)\n",
            "  13. xls                  (score: 6.1880)\n",
            "  14. stinson              (score: 6.1014)\n",
            "  15. ferc                 (score: 6.0785)\n",
            "  16. daren                (score: 6.0330)\n",
            "  17. sitara               (score: 6.0078)\n",
            "  18. epmi                 (score: 5.9854)\n",
            "  19. louise               (score: 5.9531)\n",
            "  20. dynegy               (score: 5.9162)\n"
          ]
        }
      ],
      "source": [
        "get_top_words_per_class(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKm0uLBWaHN2"
      },
      "source": [
        "### 5.2 Thử nghiệm với các tham số smoothing khác nhau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drm_1yP4aHN2",
        "outputId": "d7bd02c0-60bf-4183-84e1-6ebe4b50444f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== THỬ NGHIỆM VỚI CÁC GIÁ TRỊ ALPHA KHÁC NHAU ===\n",
            "\n",
            "Alpha = 0.1\n",
            "Tính prior probability...\n",
            "P(spam) = 0.3608\n",
            "P(ham) = 0.6392\n",
            "\n",
            "Đang đếm từ...\n",
            "Kích thước từ vựng: 105797\n",
            "\n",
            "Tính likelihood với Laplace smoothing...\n",
            "\n",
            "Lớp spam: 821355 từ\n",
            "\n",
            "Lớp ham: 1638569 từ\n",
            "\n",
            "Huấn luyện hoàn tất!\n",
            "Validation Accuracy: 0.9822\n",
            "\n",
            "Alpha = 0.5\n",
            "Tính prior probability...\n",
            "P(spam) = 0.3608\n",
            "P(ham) = 0.6392\n",
            "\n",
            "Đang đếm từ...\n",
            "Kích thước từ vựng: 105797\n",
            "\n",
            "Tính likelihood với Laplace smoothing...\n",
            "\n",
            "Lớp spam: 821355 từ\n",
            "\n",
            "Lớp ham: 1638569 từ\n",
            "\n",
            "Huấn luyện hoàn tất!\n",
            "Validation Accuracy: 0.9812\n",
            "\n",
            "Alpha = 1.0\n",
            "Tính prior probability...\n",
            "P(spam) = 0.3608\n",
            "P(ham) = 0.6392\n",
            "\n",
            "Đang đếm từ...\n",
            "Kích thước từ vựng: 105797\n",
            "\n",
            "Tính likelihood với Laplace smoothing...\n",
            "\n",
            "Lớp spam: 821355 từ\n",
            "\n",
            "Lớp ham: 1638569 từ\n",
            "\n",
            "Huấn luyện hoàn tất!\n",
            "Validation Accuracy: 0.9812\n",
            "\n",
            "Alpha = 2.0\n",
            "Tính prior probability...\n",
            "P(spam) = 0.3608\n",
            "P(ham) = 0.6392\n",
            "\n",
            "Đang đếm từ...\n",
            "Kích thước từ vựng: 105797\n",
            "\n",
            "Tính likelihood với Laplace smoothing...\n",
            "\n",
            "Lớp spam: 821355 từ\n",
            "\n",
            "Lớp ham: 1638569 từ\n",
            "\n",
            "Huấn luyện hoàn tất!\n",
            "Validation Accuracy: 0.9786\n",
            "\n",
            "Alpha = 5.0\n",
            "Tính prior probability...\n",
            "P(spam) = 0.3608\n",
            "P(ham) = 0.6392\n",
            "\n",
            "Đang đếm từ...\n",
            "Kích thước từ vựng: 105797\n",
            "\n",
            "Tính likelihood với Laplace smoothing...\n",
            "\n",
            "Lớp spam: 821355 từ\n",
            "\n",
            "Lớp ham: 1638569 từ\n",
            "\n",
            "Huấn luyện hoàn tất!\n",
            "Validation Accuracy: 0.9692\n",
            "\n",
            "Alpha tốt nhất: 0.1 với accuracy: 0.9822\n"
          ]
        }
      ],
      "source": [
        "print(\"=== THỬ NGHIỆM VỚI CÁC GIÁ TRỊ ALPHA KHÁC NHAU ===\")\n",
        "\n",
        "alphas = [0.1, 0.5, 1.0, 2.0, 5.0]\n",
        "results = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    print(f\"\\nAlpha = {alpha}\")\n",
        "\n",
        "    # Train model với alpha mới\n",
        "    nb_temp = NaiveBayesClassifier(alpha=alpha)\n",
        "    nb_temp.fit(X_train, y_train)\n",
        "\n",
        "    # Đánh giá\n",
        "    val_pred = nb_temp.predict(X_val)\n",
        "    accuracy, _ = evaluate_model(y_val, val_pred)\n",
        "\n",
        "    results.append({'alpha': alpha, 'accuracy': accuracy})\n",
        "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Tìm alpha tốt nhất\n",
        "best_result = max(results, key=lambda x: x['accuracy'])\n",
        "print(f\"\\nAlpha tốt nhất: {best_result['alpha']} với accuracy: {best_result['accuracy']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_1cxjS1hTUQ",
        "outputId": "7c347a4e-9480-473e-c763-a2f2ca0680f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tính prior probability...\n",
            "P(spam) = 0.3608\n",
            "P(ham) = 0.6392\n",
            "\n",
            "Đang đếm từ...\n",
            "Kích thước từ vựng: 105797\n",
            "\n",
            "Tính likelihood với Laplace smoothing...\n",
            "\n",
            "Lớp spam: 821355 từ\n",
            "\n",
            "Lớp ham: 1638569 từ\n",
            "\n",
            "Huấn luyện hoàn tất!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<__main__.NaiveBayesClassifier at 0x7d7783f2b990>"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# áp dụng alpha tốt nhất\n",
        "nb_classifier.alpha = best_result['alpha']\n",
        "nb_classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQLu3aiBaHN2"
      },
      "source": [
        "## 6. Ví dụ test thực tế"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "atZliJKCaHN2"
      },
      "outputs": [],
      "source": [
        "test_emails = [\n",
        "    {\n",
        "        'subject': 'Congratulations! You have won 1 million dollars',\n",
        "        'message': 'Click here now to claim your prize. Limited time offer!'\n",
        "    },\n",
        "    {\n",
        "        'subject': 'Project Team Meeting',\n",
        "        'message': 'Hi team, we will have a meeting tomorrow at 2 PM to discuss the project progress.'\n",
        "    },\n",
        "    {\n",
        "        'subject': '90% OFF - BUY NOW',\n",
        "        'message': 'Special promotion for today only! Buy now or you will miss out!!!'\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oK8kkYPaHN3",
        "outputId": "b0b576fc-d27a-4b6f-d9af-02f557e7837c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== TEST VỚI CÁC EMAIL MẪU ===\n",
            "\n",
            "Email 1:\n",
            "Tiêu đề: \"Congratulations! You have won 1 million dollars\"\n",
            "Nội dung: \"Click here now to claim your prize. Limited time offer!...\"\n",
            "Dự đoán: SPAM\n",
            "Xác suất:\n",
            "  - spam: 0.9999\n",
            "  - ham: 0.0001\n",
            "\n",
            "Email 2:\n",
            "Tiêu đề: \"Project Team Meeting\"\n",
            "Nội dung: \"Hi team, we will have a meeting tomorrow at 2 PM to discuss the project progress....\"\n",
            "Dự đoán: HAM\n",
            "Xác suất:\n",
            "  - spam: 0.0000\n",
            "  - ham: 1.0000\n",
            "\n",
            "Email 3:\n",
            "Tiêu đề: \"90% OFF - BUY NOW\"\n",
            "Nội dung: \"Special promotion for today only! Buy now or you will miss out!!!...\"\n",
            "Dự đoán: SPAM\n",
            "Xác suất:\n",
            "  - spam: 0.9861\n",
            "  - ham: 0.0139\n"
          ]
        }
      ],
      "source": [
        "print(\"=== TEST VỚI CÁC EMAIL MẪU ===\")\n",
        "for i, email in enumerate(test_emails, 1):\n",
        "    print(f\"\\nEmail {i}:\")\n",
        "    print(f\"Tiêu đề: \\\"{email['subject']}\\\"\")\n",
        "    print(f\"Nội dung: \\\"{email['message'][:100]}...\\\"\")\n",
        "\n",
        "    # Tiền xử lý và dự đoán\n",
        "    combined = preprocess_text(email['subject']) + ' ' + preprocess_text(email['message'])\n",
        "    prediction, log_pros = nb_classifier._predict_single(combined)\n",
        "\n",
        "    print(f\"Dự đoán: {prediction.upper()}\")\n",
        "\n",
        "    max_log_prob = max(log_pros.values())\n",
        "    exp_probs = {c: math.exp(log_prob - max_log_prob) for c, log_prob in log_pros.items()}\n",
        "    total = sum(exp_probs.values())\n",
        "    final_probs = {c: exp_prob / total for c, exp_prob in exp_probs.items()}\n",
        "\n",
        "    print(f\"Xác suất:\")\n",
        "    print(f\"  - spam: {final_probs.get('spam', 0):.4f}\")\n",
        "    print(f\"  - ham: {final_probs.get('ham', 0):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kLIegdIaHN3"
      },
      "source": [
        "## 7. Kết luận\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjvzKSDnaHN3",
        "outputId": "4e1f0fba-1600-4764-f2a9-9ad08d30993c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== TÓM TẮT KẾT QUẢ ===\n",
            "1. Kích thước dữ liệu:\n",
            "   - Train: 17252 emails\n",
            "   - Validation: 3084 emails\n",
            "   - Từ vựng: 105797 từ\n",
            "\n",
            "2. Hiệu suất mô hình:\n",
            "   - Train accuracy: 0.9870\n",
            "   - Validation accuracy: 0.9812\n",
            "\n",
            "3. Tham số mô hình:\n",
            "   - Smoothing (alpha): 0.1\n",
            "   - Phương pháp: Naive Bayes với Laplace smoothing\n",
            "\n",
            "4. Ưu điểm của mô hình:\n",
            "   - Đơn giản, dễ hiểu và cài đặt\n",
            "   - Huấn luyện nhanh\n",
            "   - Hoạt động tốt với dữ liệu văn bản\n",
            "   - Xử lý tốt với từ chưa xuất hiện nhờ smoothing\n",
            "\n",
            "5. Hạn chế và cải thiện:\n",
            "   - Giả định độc lập có điều kiện có thể không phù hợp\n",
            "   - Có thể cải thiện bằng cách:\n",
            "     + Sử dụng n-grams thay vì unigrams\n",
            "     + Feature engineering tốt hơn\n",
            "     + Kết hợp với các đặc trưng khác (độ dài email, số lượng ký tự đặc biệt, ...)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n=== TÓM TẮT KẾT QUẢ ===\")\n",
        "print(f\"1. Kích thước dữ liệu:\")\n",
        "print(f\"   - Train: {len(train_data)} emails\")\n",
        "print(f\"   - Validation: {len(val_data)} emails\")\n",
        "print(f\"   - Từ vựng: {len(nb_classifier.vocab)} từ\")\n",
        "\n",
        "print(f\"\\n2. Hiệu suất mô hình:\")\n",
        "print(f\"   - Train accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"   - Validation accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "print(f\"\\n3. Tham số mô hình:\")\n",
        "print(f\"   - Smoothing (alpha): {nb_classifier.alpha}\")\n",
        "print(f\"   - Phương pháp: Naive Bayes với Laplace smoothing\")\n",
        "\n",
        "print(\"\\n4. Ưu điểm của mô hình:\")\n",
        "print(\"   - Đơn giản, dễ hiểu và cài đặt\")\n",
        "print(\"   - Huấn luyện nhanh\")\n",
        "print(\"   - Hoạt động tốt với dữ liệu văn bản\")\n",
        "print(\"   - Xử lý tốt với từ chưa xuất hiện nhờ smoothing\")\n",
        "\n",
        "print(\"\\n5. Hạn chế và cải thiện:\")\n",
        "print(\"   - Giả định độc lập có điều kiện có thể không phù hợp\")\n",
        "print(\"   - Có thể cải thiện bằng cách:\")\n",
        "print(\"     + Sử dụng n-grams thay vì unigrams\")\n",
        "print(\"     + Feature engineering tốt hơn\")\n",
        "print(\"     + Kết hợp với các đặc trưng khác (độ dài email, số lượng ký tự đặc biệt, ...)\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
