{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 - Phân loại thư rác với Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thông tin nhóm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import thư viện và tải dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu\n",
    "print(\"Đang tải dữ liệu...\")\n",
    "train_data = pd.read_csv('train.csv')\n",
    "val_data = pd.read_csv('val.csv')\n",
    "\n",
    "print(f\"Kích thước tập train: {train_data.shape}\")\n",
    "print(f\"Kích thước tập validation: {val_data.shape}\")\n",
    "print(\"\\n5 dòng đầu tiên của tập train:\")\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tiền xử lý dữ liệu "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Kiểm tra và làm sạch dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra dữ liệu null\n",
    "print(\"Kiểm tra dữ liệu null:\")\n",
    "print(train_data.isnull().sum())\n",
    "print(\"\\nKiểm tra dữ liệu null trong val set:\")\n",
    "print(val_data.isnull().sum())\n",
    "\n",
    "# Điền giá trị rỗng cho Message nếu có\n",
    "train_data['Message'] = train_data['Message'].fillna('')\n",
    "val_data['Message'] = val_data['Message'].fillna('')\n",
    "\n",
    "# Kiểm tra dữ liệu trùng lặp\n",
    "print(f\"\\nSố dòng trùng lặp trong train: {train_data.duplicated().sum()}\")\n",
    "print(f\"Số dòng trùng lặp trong val: {val_data.duplicated().sum()}\")\n",
    "\n",
    "# Loại bỏ dòng trùng lặp nếu có\n",
    "train_data = train_data.drop_duplicates().reset_index(drop=True)\n",
    "val_data = val_data.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Kiểm tra phân phối nhãn\n",
    "print(\"\\nPhân phối nhãn trong tập train:\")\n",
    "print(train_data['Spam/Ham'].value_counts())\n",
    "print(\"\\nPhân phối nhãn trong tập val:\")\n",
    "print(val_data['Spam/Ham'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Tiền xử lý văn bản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Tiền xử lý văn bản:\n",
    "    - Chuyển về chữ thường\n",
    "    - Loại bỏ ký tự đặc biệt, giữ lại chữ và số\n",
    "    - Loại bỏ khoảng trắng thừa\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Chuyển về chữ thường\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Loại bỏ các ký tự đặc biệt, giữ lại chữ, số và khoảng trắng\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    \n",
    "    # Loại bỏ khoảng trắng thừa\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Áp dụng tiền xử lý cho dữ liệu\n",
    "print(\"Đang tiền xử lý văn bản...\")\n",
    "train_data['processed_subject'] = train_data['Subject'].apply(preprocess_text)\n",
    "train_data['processed_message'] = train_data['Message'].apply(preprocess_text)\n",
    "train_data['combined_text'] = train_data['processed_subject'] + ' ' + train_data['processed_message']\n",
    "\n",
    "val_data['processed_subject'] = val_data['Subject'].apply(preprocess_text)\n",
    "val_data['processed_message'] = val_data['Message'].apply(preprocess_text)\n",
    "val_data['combined_text'] = val_data['processed_subject'] + ' ' + val_data['processed_message']\n",
    "\n",
    "print(\"Ví dụ văn bản sau khi tiền xử lý:\")\n",
    "print(train_data[['Subject', 'processed_subject']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Xây dựng mô hình Naive Bayes từ đầu "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Lý thuyết Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes Classifier cho phân loại văn bản:\n",
    "\n",
    "1. Theo Bayes' theorem:\n",
    "   P(class|document) = P(document|class) * P(class) / P(document)\n",
    "\n",
    "2. Với giả định Naive Bayes (độc lập có điều kiện):\n",
    "   P(document|class) = P(word1|class) * P(word2|class) * ... * P(wordn|class)\n",
    "\n",
    "3. Sử dụng log probability để tránh underflow:\n",
    "   log P(class|document) = log P(class) + Σ log P(word|class)\n",
    "\n",
    "4. Laplace smoothing để xử lý từ chưa xuất hiện:\n",
    "   P(word|class) = (count(word, class) + α) / (count(all words in class) + α * |V|)\n",
    "   với α = 1 (Laplace smoothing), |V| là kích thước từ vựng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Cài đặt Naive Bayes Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        \"\"\"\n",
    "        Khởi tạo Naive Bayes Classifier\n",
    "        \n",
    "        Parameters:\n",
    "        - alpha: Tham số smoothing (mặc định = 1.0 cho Laplace smoothing)\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.class_priors = {}\n",
    "        self.word_probs = {}\n",
    "        self.classes = []\n",
    "        self.vocab = set()\n",
    "        \n",
    "    def _tokenize(self, text):\n",
    "        \"\"\"Tách văn bản thành các từ\"\"\"\n",
    "        return text.split()\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Huấn luyện mô hình Naive Bayes\n",
    "        \n",
    "        Parameters:\n",
    "        - X_train: Danh sách văn bản đã tiền xử lý\n",
    "        - y_train: Nhãn tương ứng\n",
    "        \"\"\"\n",
    "        # Lấy danh sách các lớp\n",
    "        self.classes = list(set(y_train))\n",
    "        n_docs = len(y_train)\n",
    "        \n",
    "        # Tính prior probability cho mỗi lớp\n",
    "        print(\"Tính prior probability...\")\n",
    "        for c in self.classes:\n",
    "            self.class_priors[c] = sum(1 for y in y_train if y == c) / n_docs\n",
    "            print(f\"P({c}) = {self.class_priors[c]:.4f}\")\n",
    "        \n",
    "        # Đếm từ cho mỗi lớp\n",
    "        word_counts = {c: Counter() for c in self.classes}\n",
    "        doc_counts = {c: 0 for c in self.classes}\n",
    "        \n",
    "        print(\"\\nĐang đếm từ...\")\n",
    "        for text, label in zip(X_train, y_train):\n",
    "            words = self._tokenize(text)\n",
    "            doc_counts[label] += 1\n",
    "            for word in words:\n",
    "                word_counts[label][word] += 1\n",
    "                self.vocab.add(word)\n",
    "        \n",
    "        vocab_size = len(self.vocab)\n",
    "        print(f\"Kích thước từ vựng: {vocab_size}\")\n",
    "        \n",
    "        # Tính likelihood với Laplace smoothing\n",
    "        print(\"\\nTính likelihood với Laplace smoothing...\")\n",
    "        self.word_probs = {c: {} for c in self.classes}\n",
    "        \n",
    "        for c in self.classes:\n",
    "            total_words = sum(word_counts[c].values())\n",
    "            print(f\"\\nLớp {c}: {total_words} từ\")\n",
    "            \n",
    "            # Tính P(word|class) cho mỗi từ trong vocabulary\n",
    "            for word in self.vocab:\n",
    "                count = word_counts[c].get(word, 0)\n",
    "                # Laplace smoothing\n",
    "                self.word_probs[c][word] = (count + self.alpha) / (total_words + self.alpha * vocab_size)\n",
    "            \n",
    "            # Tính xác suất cho từ chưa từng xuất hiện (unknown words)\n",
    "            self.word_probs[c]['<UNK>'] = self.alpha / (total_words + self.alpha * vocab_size)\n",
    "        \n",
    "        print(\"\\nHuấn luyện hoàn tất!\")\n",
    "        return self\n",
    "    \n",
    "    def _predict_single(self, text):\n",
    "        \"\"\"\n",
    "        Dự đoán nhãn cho một văn bản\n",
    "        \n",
    "        Returns: (predicted_class, log_probabilities)\n",
    "        \"\"\"\n",
    "        words = self._tokenize(text)\n",
    "        \n",
    "        # Tính log probability cho mỗi lớp\n",
    "        log_probs = {}\n",
    "        \n",
    "        for c in self.classes:\n",
    "            # Bắt đầu với log prior\n",
    "            log_prob = math.log(self.class_priors[c])\n",
    "            \n",
    "            # Cộng log likelihood của mỗi từ\n",
    "            for word in words:\n",
    "                if word in self.word_probs[c]:\n",
    "                    log_prob += math.log(self.word_probs[c][word])\n",
    "                else:\n",
    "                    # Từ chưa xuất hiện, sử dụng xác suất UNK\n",
    "                    log_prob += math.log(self.word_probs[c]['<UNK>'])\n",
    "            \n",
    "            log_probs[c] = log_prob\n",
    "        \n",
    "        # Chọn lớp có log probability cao nhất\n",
    "        predicted_class = max(log_probs, key=log_probs.get)\n",
    "        \n",
    "        return predicted_class, log_probs\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Dự đoán nhãn cho tập văn bản\"\"\"\n",
    "        predictions = []\n",
    "        for text in X_test:\n",
    "            pred, _ = self._predict_single(text)\n",
    "            predictions.append(pred)\n",
    "        return predictions\n",
    "    \n",
    "    def predict_proba(self, X_test):\n",
    "        \"\"\"\n",
    "        Dự đoán xác suất cho mỗi lớp\n",
    "        \n",
    "        Returns: List of dictionaries với xác suất cho mỗi lớp\n",
    "        \"\"\"\n",
    "        proba_list = []\n",
    "        \n",
    "        for text in X_test:\n",
    "            _, log_probs = self._predict_single(text)\n",
    "            \n",
    "            # Chuyển log probabilities về probabilities\n",
    "            # Sử dụng log-sum-exp trick để tránh overflow\n",
    "            max_log_prob = max(log_probs.values())\n",
    "            exp_probs = {c: math.exp(log_prob - max_log_prob) \n",
    "                        for c, log_prob in log_probs.items()}\n",
    "            \n",
    "            # Normalize\n",
    "            total = sum(exp_probs.values())\n",
    "            probs = {c: exp_prob / total for c, exp_prob in exp_probs.items()}\n",
    "            \n",
    "            proba_list.append(probs)\n",
    "        \n",
    "        return proba_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo và huấn luyện mô hình\n",
    "nb_classifier = NaiveBayesClassifier(alpha=1.0)\n",
    "\n",
    "# Chuẩn bị dữ liệu\n",
    "X_train = train_data['combined_text'].values\n",
    "y_train = train_data['Spam/Ham'].values\n",
    "\n",
    "print(\"Bắt đầu huấn luyện mô hình...\")\n",
    "nb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Đánh giá mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Đánh giá mô hình với các metrics:\n",
    "    - Accuracy\n",
    "    - Precision, Recall, F1-score cho mỗi lớp\n",
    "    - Confusion Matrix\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = sum(y_t == y_p for y_t, y_p in zip(y_true, y_pred)) / len(y_true)\n",
    "    \n",
    "    # Confusion Matrix và metrics cho mỗi lớp\n",
    "    classes = list(set(y_true))\n",
    "    metrics = {}\n",
    "    \n",
    "    for c in classes:\n",
    "        # True Positive, False Positive, False Negative, True Negative\n",
    "        tp = sum((y_t == c) and (y_p == c) for y_t, y_p in zip(y_true, y_pred))\n",
    "        fp = sum((y_t != c) and (y_p == c) for y_t, y_p in zip(y_true, y_pred))\n",
    "        fn = sum((y_t == c) and (y_p != c) for y_t, y_p in zip(y_true, y_pred))\n",
    "        tn = sum((y_t != c) and (y_p != c) for y_t, y_p in zip(y_true, y_pred))\n",
    "        \n",
    "        # Precision, Recall, F1\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        metrics[c] = {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'tp': tp, 'fp': fp, 'fn': fn, 'tn': tn\n",
    "        }\n",
    "    \n",
    "    return accuracy, metrics\n",
    "\n",
    "# Đánh giá trên tập train\n",
    "print(\"Đánh giá trên tập train:\")\n",
    "train_predictions = nb_classifier.predict(X_train)\n",
    "train_accuracy, train_metrics = evaluate_model(y_train, train_predictions)\n",
    "\n",
    "print(f\"Accuracy: {train_accuracy:.4f}\")\n",
    "for c in train_metrics:\n",
    "    m = train_metrics[c]\n",
    "    print(f\"\\nLớp '{c}':\")\n",
    "    print(f\"  Precision: {m['precision']:.4f}\")\n",
    "    print(f\"  Recall: {m['recall']:.4f}\")\n",
    "    print(f\"  F1-score: {m['f1']:.4f}\")\n",
    "\n",
    "# Đánh giá trên tập validation\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Đánh giá trên tập validation:\")\n",
    "X_val = val_data['combined_text'].values\n",
    "y_val = val_data['Spam/Ham'].values\n",
    "\n",
    "val_predictions = nb_classifier.predict(X_val)\n",
    "val_accuracy, val_metrics = evaluate_model(y_val, val_predictions)\n",
    "\n",
    "print(f\"Accuracy: {val_accuracy:.4f}\")\n",
    "for c in val_metrics:\n",
    "    m = val_metrics[c]\n",
    "    print(f\"\\nLớp '{c}':\")\n",
    "    print(f\"  Precision: {m['precision']:.4f}\")\n",
    "    print(f\"  Recall: {m['recall']:.4f}\")\n",
    "    print(f\"  F1-score: {m['f1']:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix (Val set):\")\n",
    "print(\"Predicted ->\")\n",
    "print(\"Actual ↓    spam    ham\")\n",
    "for true_class in ['spam', 'ham']:\n",
    "    print(f\"{true_class:8s}\", end=\"\")\n",
    "    for pred_class in ['spam', 'ham']:\n",
    "        count = sum((y_t == true_class) and (y_p == pred_class) \n",
    "                   for y_t, y_p in zip(y_val, val_predictions))\n",
    "        print(f\"{count:8d}\", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Thử nghiệm thực tế"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Chức năng 1: Dự đoán email người dùng nhập"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_user_email():\n",
    "    \"\"\"\n",
    "    Cho phép người dùng nhập email và dự đoán spam/ham\n",
    "    \"\"\"\n",
    "    print(\"=== DỰ ĐOÁN EMAIL ===\")\n",
    "    subject = input(\"Nhập tiêu đề email: \")\n",
    "    message = input(\"Nhập nội dung email: \")\n",
    "    \n",
    "    # Tiền xử lý\n",
    "    processed_subject = preprocess_text(subject)\n",
    "    processed_message = preprocess_text(message)\n",
    "    combined = processed_subject + ' ' + processed_message\n",
    "    \n",
    "    # Dự đoán\n",
    "    prediction, log_probs = nb_classifier._predict_single(combined)\n",
    "    \n",
    "    # Tính xác suất\n",
    "    max_log_prob = max(log_probs.values())\n",
    "    exp_probs = {c: math.exp(log_prob - max_log_prob) \n",
    "                for c, log_prob in log_probs.items()}\n",
    "    total = sum(exp_probs.values())\n",
    "    probs = {c: exp_prob / total for c, exp_prob in exp_probs.items()}\n",
    "    \n",
    "    print(f\"\\nKết quả dự đoán: {prediction.upper()}\")\n",
    "    print(f\"Xác suất spam: {probs['spam']:.4f}\")\n",
    "    print(f\"Xác suất ham: {probs['ham']:.4f}\")\n",
    "    \n",
    "    return prediction, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test chức năng\n",
    "# predict_user_email()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Chức năng 2: Đánh giá file CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_csv_file(filename):\n",
    "    \"\"\"\n",
    "    Đọc và đánh giá mô hình trên file CSV\n",
    "    File CSV cần có cấu trúc giống val.csv\n",
    "    \"\"\"\n",
    "    print(f\"=== ĐÁNH GIÁ FILE: {filename} ===\")\n",
    "    \n",
    "    try:\n",
    "        # Đọc file\n",
    "        data = pd.read_csv(filename)\n",
    "        print(f\"Đã đọc {len(data)} dòng từ file\")\n",
    "        \n",
    "        # Kiểm tra cấu trúc\n",
    "        required_cols = ['Subject', 'Message', 'Spam/Ham']\n",
    "        if not all(col in data.columns for col in required_cols):\n",
    "            print(\"Lỗi: File không có đủ các cột cần thiết!\")\n",
    "            print(f\"Cần có: {required_cols}\")\n",
    "            print(f\"File có: {list(data.columns)}\")\n",
    "            return\n",
    "        \n",
    "        # Tiền xử lý\n",
    "        data['Message'] = data['Message'].fillna('')\n",
    "        data['processed_subject'] = data['Subject'].apply(preprocess_text)\n",
    "        data['processed_message'] = data['Message'].apply(preprocess_text)\n",
    "        data['combined_text'] = data['processed_subject'] + ' ' + data['processed_message']\n",
    "        \n",
    "        # Dự đoán\n",
    "        X_test = data['combined_text'].values\n",
    "        y_test = data['Spam/Ham'].values\n",
    "        predictions = nb_classifier.predict(X_test)\n",
    "        \n",
    "        # Đánh giá\n",
    "        accuracy, metrics = evaluate_model(y_test, predictions)\n",
    "        \n",
    "        print(f\"\\nKết quả đánh giá:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        for c in metrics:\n",
    "            m = metrics[c]\n",
    "            print(f\"\\nLớp '{c}':\")\n",
    "            print(f\"  Precision: {m['precision']:.4f}\")\n",
    "            print(f\"  Recall: {m['recall']:.4f}\")\n",
    "            print(f\"  F1-score: {m['f1']:.4f}\")\n",
    "        \n",
    "        # Chi tiết một số dự đoán\n",
    "        print(\"\\n5 dự đoán đầu tiên:\")\n",
    "        for i in range(min(5, len(data))):\n",
    "            print(f\"{i+1}. Thực tế: {y_test[i]}, Dự đoán: {predictions[i]}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test với file val.csv\n",
    "# evaluate_csv_file('val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Phân tích và cải thiện\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Phân tích các từ quan trọng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words_per_class(n=20):\n",
    "    \"\"\"\n",
    "    Lấy n từ có xác suất cao nhất cho mỗi lớp\n",
    "    \"\"\"\n",
    "    print(f\"=== TOP {n} TỪ QUAN TRỌNG CHO MỖI LỚP ===\")\n",
    "    \n",
    "    for c in nb_classifier.classes:\n",
    "        # Lấy log odds ratio: log(P(word|class)) - log(P(word|not_class))\n",
    "        word_scores = {}\n",
    "        \n",
    "        for word in nb_classifier.vocab:\n",
    "            if word in nb_classifier.word_probs[c]:\n",
    "                # Log probability của từ trong lớp hiện tại\n",
    "                log_prob_c = math.log(nb_classifier.word_probs[c][word])\n",
    "                \n",
    "                # Log probability trung bình của từ trong các lớp khác\n",
    "                other_classes = [cls for cls in nb_classifier.classes if cls != c]\n",
    "                avg_log_prob_other = sum(math.log(nb_classifier.word_probs[cls].get(word, \n",
    "                                                  nb_classifier.word_probs[cls]['<UNK>'])) \n",
    "                                        for cls in other_classes) / len(other_classes)\n",
    "                \n",
    "                # Score = difference\n",
    "                word_scores[word] = log_prob_c - avg_log_prob_other\n",
    "        \n",
    "        # Sắp xếp và lấy top n\n",
    "        top_words = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "        \n",
    "        print(f\"\\nLớp '{c}':\")\n",
    "        for i, (word, score) in enumerate(top_words, 1):\n",
    "            print(f\"  {i:2d}. {word:20s} (score: {score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_words_per_class(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Thử nghiệm với các tham số smoothing khác nhau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== THỬ NGHIỆM VỚI CÁC GIÁ TRỊ ALPHA KHÁC NHAU ===\")\n",
    "\n",
    "alphas = [0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(f\"\\nAlpha = {alpha}\")\n",
    "    \n",
    "    # Train model với alpha mới\n",
    "    nb_temp = NaiveBayesClassifier(alpha=alpha)\n",
    "    nb_temp.fit(X_train, y_train)\n",
    "    \n",
    "    # Đánh giá\n",
    "    val_pred = nb_temp.predict(X_val)\n",
    "    accuracy, _ = evaluate_model(y_val, val_pred)\n",
    "    \n",
    "    results.append({'alpha': alpha, 'accuracy': accuracy})\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Tìm alpha tốt nhất\n",
    "best_result = max(results, key=lambda x: x['accuracy'])\n",
    "print(f\"\\nAlpha tốt nhất: {best_result['alpha']} với accuracy: {best_result['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ví dụ test thực tế"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emails = [\n",
    "    {\n",
    "        'subject': 'Chúc mừng! Bạn đã trúng thưởng 1 triệu đô la',\n",
    "        'message': 'Click vào đây ngay để nhận giải thưởng của bạn. Ưu đãi có hạn!'\n",
    "    },\n",
    "    {\n",
    "        'subject': 'Họp nhóm dự án',\n",
    "        'message': 'Chào các bạn, ngày mai chúng ta sẽ họp lúc 2h chiều để thảo luận về tiến độ dự án.'\n",
    "    },\n",
    "    {\n",
    "        'subject': 'GIẢM GIÁ 90% - MUA NGAY',\n",
    "        'message': 'Khuyến mãi đặc biệt chỉ hôm nay! Mua ngay kẻo lỡ!!!'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== TEST VỚI CÁC EMAIL MẪU ===\")\n",
    "for i, email in enumerate(test_emails, 1):\n",
    "    print(f\"\\nEmail {i}:\")\n",
    "    print(f\"Tiêu đề: {email['subject']}\")\n",
    "    print(f\"Nội dung: {email['message'][:50]}...\")\n",
    "    \n",
    "    # Tiền xử lý và dự đoán\n",
    "    combined = preprocess_text(email['subject']) + ' ' + preprocess_text(email['message'])\n",
    "    prediction, _ = nb_classifier._predict_single(combined)\n",
    "    \n",
    "    print(f\"Dự đoán: {prediction.upper()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Kết luận\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== TÓM TẮT KẾT QUẢ ===\")\n",
    "print(f\"1. Kích thước dữ liệu:\")\n",
    "print(f\"   - Train: {len(train_data)} emails\")\n",
    "print(f\"   - Validation: {len(val_data)} emails\")\n",
    "print(f\"   - Từ vựng: {len(nb_classifier.vocab)} từ\")\n",
    "\n",
    "print(f\"\\n2. Hiệu suất mô hình:\")\n",
    "print(f\"   - Train accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"   - Validation accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\n3. Tham số mô hình:\")\n",
    "print(f\"   - Smoothing (alpha): {nb_classifier.alpha}\")\n",
    "print(f\"   - Phương pháp: Naive Bayes với Laplace smoothing\")\n",
    "\n",
    "print(\"\\n4. Ưu điểm của mô hình:\")\n",
    "print(\"   - Đơn giản, dễ hiểu và cài đặt\")\n",
    "print(\"   - Huấn luyện nhanh\")\n",
    "print(\"   - Hoạt động tốt với dữ liệu văn bản\")\n",
    "print(\"   - Xử lý tốt với từ chưa xuất hiện nhờ smoothing\")\n",
    "\n",
    "print(\"\\n5. Hạn chế và cải thiện:\")\n",
    "print(\"   - Giả định độc lập có điều kiện có thể không phù hợp\")\n",
    "print(\"   - Có thể cải thiện bằng cách:\")\n",
    "print(\"     + Sử dụng n-grams thay vì unigrams\")\n",
    "print(\"     + Feature engineering tốt hơn\")\n",
    "print(\"     + Kết hợp với các đặc trưng khác (độ dài email, số lượng ký tự đặc biệt, ...)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
